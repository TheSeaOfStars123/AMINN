epoch-100:
D:\ProgramData\Anaconda3\envs\SSL4MIS\python.exe D:/Desktop/AMINN/main.py
2023-02-10 20:57:07.435975: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-02-10 20:57:07.436083: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-02-10 20:57:09.618089: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-10 20:57:09.618925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2023-02-10 20:57:09.643189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1660 SUPER computeCapability: 7.5
coreClock: 1.785GHz coreCount: 22 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2023-02-10 20:57:09.645852: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-02-10 20:57:09.648503: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2023-02-10 20:57:09.650973: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2023-02-10 20:57:09.654129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2023-02-10 20:57:09.655321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2023-02-10 20:57:09.659175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2023-02-10 20:57:09.661585: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2023-02-10 20:57:09.663884: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2023-02-10 20:57:09.663974: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2023-02-10 20:57:09.664374: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-10 20:57:09.665066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-02-10 20:57:09.665155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]
2023-02-10 20:57:09.665210: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-10 20:57:11.061771: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
epoch= 0    train_loss = 3.292781    bag_loss = 0.674993    mse_loss = 1.188396 train_acc=0.644330    test_loss = 3.348356    test_acc=0.642857
epoch= 1    train_loss = 3.078618    bag_loss = 0.634707    mse_loss = 1.177865 train_acc=0.644330    test_loss = 3.142864    test_acc=0.642857
epoch= 2    train_loss = 2.898755    bag_loss = 0.605934    mse_loss = 1.156418 train_acc=0.644330    test_loss = 2.972415    test_acc=0.642857
epoch= 3    train_loss = 2.743676    bag_loss = 0.589666    mse_loss = 1.122314 train_acc=0.644330    test_loss = 2.825502    test_acc=0.642857
epoch= 4    train_loss = 2.606012    bag_loss = 0.579992    mse_loss = 1.079849 train_acc=0.644330    test_loss = 2.697438    test_acc=0.642857
epoch= 5    train_loss = 2.486718    bag_loss = 0.573545    mse_loss = 1.038502 train_acc=0.644330    test_loss = 2.582433    test_acc=0.642857
epoch= 6    train_loss = 2.379947    bag_loss = 0.569064    mse_loss = 0.996742 train_acc=0.644330    test_loss = 2.474383    test_acc=0.642857
epoch= 7    train_loss = 2.280301    bag_loss = 0.566134    mse_loss = 0.951430 train_acc=0.649485    test_loss = 2.371253    test_acc=0.673469
epoch= 8    train_loss = 2.189301    bag_loss = 0.564406    mse_loss = 0.906171 train_acc=0.685567    test_loss = 2.280036    test_acc=0.704082
epoch= 9    train_loss = 2.112168    bag_loss = 0.563576    mse_loss = 0.868546 train_acc=0.701031    test_loss = 2.206648    test_acc=0.714286
epoch= 10    train_loss = 2.049957    bag_loss = 0.562443    mse_loss = 0.842393 train_acc=0.690722    test_loss = 2.149647    test_acc=0.693878
epoch= 11    train_loss = 1.999315    bag_loss = 0.560545    mse_loss = 0.825495 train_acc=0.701031    test_loss = 2.103757    test_acc=0.693878
epoch= 12    train_loss = 1.956731    bag_loss = 0.558622    mse_loss = 0.813793 train_acc=0.706186    test_loss = 2.065521    test_acc=0.693878
epoch= 13    train_loss = 1.920194    bag_loss = 0.556714    mse_loss = 0.805491 train_acc=0.706186    test_loss = 2.032559    test_acc=0.704082
epoch= 14    train_loss = 1.888178    bag_loss = 0.554582    mse_loss = 0.799559 train_acc=0.711340    test_loss = 2.003159    test_acc=0.704082
epoch= 15    train_loss = 1.859900    bag_loss = 0.552846    mse_loss = 0.794872 train_acc=0.711340    test_loss = 1.976950    test_acc=0.704082
epoch= 16    train_loss = 1.834350    bag_loss = 0.550944    mse_loss = 0.791211 train_acc=0.711340    test_loss = 1.953334    test_acc=0.704082
epoch= 17    train_loss = 1.811083    bag_loss = 0.548998    mse_loss = 0.788153 train_acc=0.711340    test_loss = 1.931816    test_acc=0.693878
epoch= 18    train_loss = 1.789785    bag_loss = 0.547111    mse_loss = 0.785488 train_acc=0.721649    test_loss = 1.912170    test_acc=0.704082
epoch= 19    train_loss = 1.770231    bag_loss = 0.545274    mse_loss = 0.783168 train_acc=0.721649    test_loss = 1.894163    test_acc=0.714286
epoch= 20    train_loss = 1.752051    bag_loss = 0.543346    mse_loss = 0.781069 train_acc=0.721649    test_loss = 1.877512    test_acc=0.724490
epoch= 21    train_loss = 1.735399    bag_loss = 0.541667    mse_loss = 0.779127 train_acc=0.721649    test_loss = 1.861965    test_acc=0.724490
epoch= 22    train_loss = 1.719823    bag_loss = 0.539920    mse_loss = 0.777347 train_acc=0.726804    test_loss = 1.847666    test_acc=0.724490
epoch= 23    train_loss = 1.705232    bag_loss = 0.538178    mse_loss = 0.775673 train_acc=0.726804    test_loss = 1.834460    test_acc=0.724490
epoch= 24    train_loss = 1.691709    bag_loss = 0.536614    mse_loss = 0.774104 train_acc=0.726804    test_loss = 1.822222    test_acc=0.734694
epoch= 25    train_loss = 1.678959    bag_loss = 0.535058    mse_loss = 0.772607 train_acc=0.726804    test_loss = 1.810761    test_acc=0.744898
epoch= 26    train_loss = 1.666972    bag_loss = 0.533469    mse_loss = 0.771259 train_acc=0.726804    test_loss = 1.800068    test_acc=0.744898
epoch= 27    train_loss = 1.655726    bag_loss = 0.532025    mse_loss = 0.769923 train_acc=0.726804    test_loss = 1.790029    test_acc=0.744898
epoch= 28    train_loss = 1.644952    bag_loss = 0.530414    mse_loss = 0.768700 train_acc=0.726804    test_loss = 1.780446    test_acc=0.744898
epoch= 29    train_loss = 1.634733    bag_loss = 0.528684    mse_loss = 0.767619 train_acc=0.726804    test_loss = 1.771459    test_acc=0.744898
epoch= 30    train_loss = 1.625108    bag_loss = 0.527132    mse_loss = 0.766535 train_acc=0.726804    test_loss = 1.762897    test_acc=0.755102
epoch= 31    train_loss = 1.615924    bag_loss = 0.525609    mse_loss = 0.765473 train_acc=0.731959    test_loss = 1.754824    test_acc=0.755102
epoch= 32    train_loss = 1.607146    bag_loss = 0.524021    mse_loss = 0.764523 train_acc=0.737113    test_loss = 1.747402    test_acc=0.755102
epoch= 33    train_loss = 1.598776    bag_loss = 0.522485    mse_loss = 0.763580 train_acc=0.737113    test_loss = 1.740357    test_acc=0.755102
epoch= 34    train_loss = 1.590764    bag_loss = 0.520867    mse_loss = 0.762739 train_acc=0.742268    test_loss = 1.733630    test_acc=0.765306
epoch= 35    train_loss = 1.583216    bag_loss = 0.519393    mse_loss = 0.761891 train_acc=0.742268    test_loss = 1.727386    test_acc=0.765306
epoch= 36    train_loss = 1.575808    bag_loss = 0.517717    mse_loss = 0.761107 train_acc=0.747423    test_loss = 1.721462    test_acc=0.765306
epoch= 37    train_loss = 1.568881    bag_loss = 0.516231    mse_loss = 0.760361 train_acc=0.752577    test_loss = 1.715746    test_acc=0.775510
epoch= 38    train_loss = 1.562213    bag_loss = 0.514725    mse_loss = 0.759632 train_acc=0.757732    test_loss = 1.710373    test_acc=0.775510
epoch= 39    train_loss = 1.555822    bag_loss = 0.513212    mse_loss = 0.758954 train_acc=0.757732    test_loss = 1.705137    test_acc=0.765306
epoch= 40    train_loss = 1.549708    bag_loss = 0.511788    mse_loss = 0.758241 train_acc=0.757732    test_loss = 1.700317    test_acc=0.765306
epoch= 41    train_loss = 1.543685    bag_loss = 0.510160    mse_loss = 0.757622 train_acc=0.757732    test_loss = 1.695534    test_acc=0.765306
epoch= 42    train_loss = 1.538013    bag_loss = 0.508695    mse_loss = 0.756996 train_acc=0.762887    test_loss = 1.691316    test_acc=0.755102
epoch= 43    train_loss = 1.532415    bag_loss = 0.507072    mse_loss = 0.756430 train_acc=0.762887    test_loss = 1.686957    test_acc=0.755102
epoch= 44    train_loss = 1.527060    bag_loss = 0.505515    mse_loss = 0.755872 train_acc=0.768041    test_loss = 1.682861    test_acc=0.755102
epoch= 45    train_loss = 1.521851    bag_loss = 0.503898    mse_loss = 0.755347 train_acc=0.768041    test_loss = 1.678753    test_acc=0.755102
epoch= 46    train_loss = 1.516871    bag_loss = 0.502364    mse_loss = 0.754829 train_acc=0.768041    test_loss = 1.675402    test_acc=0.765306
epoch= 47    train_loss = 1.511889    bag_loss = 0.500622    mse_loss = 0.754370 train_acc=0.773196    test_loss = 1.671507    test_acc=0.765306
epoch= 48    train_loss = 1.507155    bag_loss = 0.499047    mse_loss = 0.753883 train_acc=0.773196    test_loss = 1.668550    test_acc=0.765306
epoch= 49    train_loss = 1.502566    bag_loss = 0.497415    mse_loss = 0.753458 train_acc=0.778351    test_loss = 1.665268    test_acc=0.755102
epoch= 50    train_loss = 1.498199    bag_loss = 0.495935    mse_loss = 0.753004 train_acc=0.783505    test_loss = 1.662112    test_acc=0.755102
epoch= 51    train_loss = 1.493959    bag_loss = 0.494461    mse_loss = 0.752580 train_acc=0.783505    test_loss = 1.659407    test_acc=0.755102
epoch= 52    train_loss = 1.489788    bag_loss = 0.492864    mse_loss = 0.752198 train_acc=0.788660    test_loss = 1.656266    test_acc=0.765306
epoch= 53    train_loss = 1.485483    bag_loss = 0.491083    mse_loss = 0.751788 train_acc=0.788660    test_loss = 1.653942    test_acc=0.765306
epoch= 54    train_loss = 1.481404    bag_loss = 0.489373    mse_loss = 0.751447 train_acc=0.783505    test_loss = 1.651596    test_acc=0.765306
epoch= 55    train_loss = 1.477393    bag_loss = 0.487668    mse_loss = 0.751064 train_acc=0.783505    test_loss = 1.648849    test_acc=0.765306
epoch= 56    train_loss = 1.473782    bag_loss = 0.486247    mse_loss = 0.750748 train_acc=0.783505    test_loss = 1.646865    test_acc=0.765306
epoch= 57    train_loss = 1.470040    bag_loss = 0.484589    mse_loss = 0.750455 train_acc=0.783505    test_loss = 1.644642    test_acc=0.765306
epoch= 58    train_loss = 1.466566    bag_loss = 0.483137    mse_loss = 0.750169 train_acc=0.783505    test_loss = 1.642698    test_acc=0.755102
epoch= 59    train_loss = 1.462844    bag_loss = 0.481360    mse_loss = 0.749879 train_acc=0.788660    test_loss = 1.641088    test_acc=0.744898
epoch= 60    train_loss = 1.459228    bag_loss = 0.479556    mse_loss = 0.749644 train_acc=0.788660    test_loss = 1.638896    test_acc=0.744898
epoch= 61    train_loss = 1.455854    bag_loss = 0.477944    mse_loss = 0.749380 train_acc=0.793814    test_loss = 1.637463    test_acc=0.744898
epoch= 62    train_loss = 1.452097    bag_loss = 0.475838    mse_loss = 0.749129 train_acc=0.798969    test_loss = 1.635719    test_acc=0.744898
epoch= 63    train_loss = 1.448517    bag_loss = 0.473805    mse_loss = 0.748909 train_acc=0.804124    test_loss = 1.634286    test_acc=0.744898
epoch= 64    train_loss = 1.445043    bag_loss = 0.471834    mse_loss = 0.748654 train_acc=0.804124    test_loss = 1.633392    test_acc=0.744898
epoch= 65    train_loss = 1.441273    bag_loss = 0.469472    mse_loss = 0.748428 train_acc=0.804124    test_loss = 1.631789    test_acc=0.744898
epoch= 66    train_loss = 1.438157    bag_loss = 0.467705    mse_loss = 0.748207 train_acc=0.804124    test_loss = 1.631321    test_acc=0.744898
epoch= 67    train_loss = 1.434725    bag_loss = 0.465533    mse_loss = 0.748009 train_acc=0.804124    test_loss = 1.630241    test_acc=0.744898
epoch= 68    train_loss = 1.431373    bag_loss = 0.463447    mse_loss = 0.747762 train_acc=0.804124    test_loss = 1.628826    test_acc=0.744898
epoch= 69    train_loss = 1.427981    bag_loss = 0.461205    mse_loss = 0.747561 train_acc=0.809278    test_loss = 1.627776    test_acc=0.744898
epoch= 70    train_loss = 1.424954    bag_loss = 0.459300    mse_loss = 0.747353 train_acc=0.809278    test_loss = 1.626831    test_acc=0.744898
epoch= 71    train_loss = 1.421365    bag_loss = 0.456771    mse_loss = 0.747154 train_acc=0.809278    test_loss = 1.626404    test_acc=0.755102
epoch= 72    train_loss = 1.417777    bag_loss = 0.454141    mse_loss = 0.746997 train_acc=0.809278    test_loss = 1.626527    test_acc=0.755102
epoch= 73    train_loss = 1.414528    bag_loss = 0.451740    mse_loss = 0.746899 train_acc=0.814433    test_loss = 1.625534    test_acc=0.755102
epoch= 74    train_loss = 1.411046    bag_loss = 0.449110    mse_loss = 0.746743 train_acc=0.814433    test_loss = 1.625027    test_acc=0.755102
epoch= 75    train_loss = 1.407553    bag_loss = 0.446422    mse_loss = 0.746595 train_acc=0.814433    test_loss = 1.624203    test_acc=0.765306
epoch= 76    train_loss = 1.404479    bag_loss = 0.444101    mse_loss = 0.746456 train_acc=0.824742    test_loss = 1.623906    test_acc=0.765306
epoch= 77    train_loss = 1.401054    bag_loss = 0.441375    mse_loss = 0.746290 train_acc=0.819588    test_loss = 1.624906    test_acc=0.755102
epoch= 78    train_loss = 1.397463    bag_loss = 0.438361    mse_loss = 0.746196 train_acc=0.819588    test_loss = 1.624704    test_acc=0.755102
epoch= 79    train_loss = 1.393851    bag_loss = 0.435332    mse_loss = 0.746049 train_acc=0.819588    test_loss = 1.624027    test_acc=0.755102
epoch= 80    train_loss = 1.390785    bag_loss = 0.432835    mse_loss = 0.745884 train_acc=0.819588    test_loss = 1.624418    test_acc=0.765306
epoch= 81    train_loss = 1.387074    bag_loss = 0.429626    mse_loss = 0.745762 train_acc=0.824742    test_loss = 1.625929    test_acc=0.755102
epoch= 82    train_loss = 1.383193    bag_loss = 0.426216    mse_loss = 0.745640 train_acc=0.824742    test_loss = 1.625889    test_acc=0.755102
epoch= 83    train_loss = 1.379686    bag_loss = 0.423138    mse_loss = 0.745492 train_acc=0.829897    test_loss = 1.626919    test_acc=0.765306
epoch= 84    train_loss = 1.375863    bag_loss = 0.419685    mse_loss = 0.745381 train_acc=0.829897    test_loss = 1.627561    test_acc=0.765306
epoch= 85    train_loss = 1.372237    bag_loss = 0.416378    mse_loss = 0.745265 train_acc=0.829897    test_loss = 1.628658    test_acc=0.765306
epoch= 86    train_loss = 1.368408    bag_loss = 0.412851    mse_loss = 0.745128 train_acc=0.829897    test_loss = 1.630321    test_acc=0.755102
epoch= 87    train_loss = 1.364382    bag_loss = 0.409049    mse_loss = 0.745043 train_acc=0.829897    test_loss = 1.632237    test_acc=0.755102
epoch= 88    train_loss = 1.360181    bag_loss = 0.405041    mse_loss = 0.744937 train_acc=0.840206    test_loss = 1.633797    test_acc=0.755102
epoch= 89    train_loss = 1.356748    bag_loss = 0.401770    mse_loss = 0.744834 train_acc=0.840206    test_loss = 1.635262    test_acc=0.744898
epoch= 90    train_loss = 1.352488    bag_loss = 0.397622    mse_loss = 0.744743 train_acc=0.845361    test_loss = 1.637300    test_acc=0.744898
epoch= 91    train_loss = 1.348826    bag_loss = 0.394005    mse_loss = 0.744655 train_acc=0.850515    test_loss = 1.637658    test_acc=0.744898
epoch= 92    train_loss = 1.343785    bag_loss = 0.388886    mse_loss = 0.744625 train_acc=0.855670    test_loss = 1.640217    test_acc=0.744898
epoch= 93    train_loss = 1.340412    bag_loss = 0.385498    mse_loss = 0.744514 train_acc=0.860825    test_loss = 1.642575    test_acc=0.734694
epoch= 94    train_loss = 1.335571    bag_loss = 0.380563    mse_loss = 0.744439 train_acc=0.860825    test_loss = 1.643284    test_acc=0.734694
epoch= 95    train_loss = 1.330992    bag_loss = 0.375848    mse_loss = 0.744373 train_acc=0.860825    test_loss = 1.646974    test_acc=0.724490
epoch= 96    train_loss = 1.326442    bag_loss = 0.371117    mse_loss = 0.744300 train_acc=0.865979    test_loss = 1.649298    test_acc=0.724490
epoch= 97    train_loss = 1.321473    bag_loss = 0.365928    mse_loss = 0.744220 train_acc=0.865979    test_loss = 1.652884    test_acc=0.724490
epoch= 98    train_loss = 1.316102    bag_loss = 0.360285    mse_loss = 0.744146 train_acc=0.865979    test_loss = 1.655454    test_acc=0.724490
[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]
[0.9874730110168457, 0.6318277716636658, 0.29402774572372437, 0.9917902946472168, 0.9026756286621094, 0.9973546266555786, 0.6783246397972107, 0.5230633020401001, 0.974259614944458, 0.9099122285842896, 0.4943947494029999, 0.7149779200553894, 0.9558383822441101, 0.8017553091049194, 0.5922617316246033, 0.925438642501831, 0.9108718633651733, 0.9583375453948975, 0.30806857347488403, 0.636457085609436, 0.8252927660942078, 0.3110613226890564, 0.6755982041358948, 0.8413782715797424, 0.9739876985549927, 0.41868525743484497, 0.3234559893608093, 0.8967114686965942, 0.929848313331604, 0.9975128173828125, 0.9765443205833435, 0.32042351365089417, 0.6118616461753845, 0.3956226706504822, 0.31887900829315186, 0.7377206087112427, 0.9874793291091919, 0.6000051498413086, 0.3748525083065033, 0.3535497784614563, 0.9734170436859131, 0.972586452960968, 0.5208860039710999, 0.3148955702781677, 0.9941655397415161, 0.8504784107208252, 0.7331355214118958, 0.9356139898300171, 0.6889464855194092, 0.4585341215133667, 0.31752485036849976, 0.31296277046203613, 0.3233543336391449, 0.345154345035553, 0.6752734184265137, 0.5681418180465698, 0.3093763589859009, 0.9965211153030396, 0.9999980330467224, 0.3314661979675293, 0.5324736833572388, 0.31352508068084717, 0.35292088985443115, 0.6175236701965332, 0.7703756093978882, 0.9880334734916687, 0.7674812078475952, 0.3150567412376404, 0.3272002339363098, 0.581548273563385, 0.4758840799331665, 0.9495258927345276, 0.4930107593536377, 0.9779250621795654, 0.9875051975250244, 0.80687415599823, 0.635479211807251, 0.5945831537246704, 0.313957154750824, 0.3043179512023926, 0.30595147609710693, 0.9968533515930176, 0.301356703042984, 0.554725170135498, 0.9002101421356201, 0.9929699897766113, 0.613275945186615, 0.9383182525634766, 0.9734548330307007, 0.3037637770175934, 0.6631838083267212, 0.6650695204734802, 0.4734337329864502, 0.41441547870635986, 0.7581296563148499, 0.35966187715530396, 0.3364078402519226, 0.8283023834228516]
epoch= 99    train_loss = 1.311010    bag_loss = 0.354905    mse_loss = 0.744044 train_acc=0.865979    test_loss = 1.658908    test_acc=0.724490
Ground truth: [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], Predicted: [0.9874730110168457, 0.6318277716636658, 0.29402774572372437, 0.9917902946472168, 0.9026756286621094, 0.9973546266555786, 0.6783246397972107, 0.5230633020401001, 0.974259614944458, 0.9099122285842896, 0.4943947494029999, 0.7149779200553894, 0.9558383822441101, 0.8017553091049194, 0.5922617316246033, 0.925438642501831, 0.9108718633651733, 0.9583375453948975, 0.30806857347488403, 0.636457085609436, 0.8252927660942078, 0.3110613226890564, 0.6755982041358948, 0.8413782715797424, 0.9739876985549927, 0.41868525743484497, 0.3234559893608093, 0.8967114686965942, 0.929848313331604, 0.9975128173828125, 0.9765443205833435, 0.32042351365089417, 0.6118616461753845, 0.3956226706504822, 0.31887900829315186, 0.7377206087112427, 0.9874793291091919, 0.6000051498413086, 0.3748525083065033, 0.3535497784614563, 0.9734170436859131, 0.972586452960968, 0.5208860039710999, 0.3148955702781677, 0.9941655397415161, 0.8504784107208252, 0.7331355214118958, 0.9356139898300171, 0.6889464855194092, 0.4585341215133667, 0.31752485036849976, 0.31296277046203613, 0.3233543336391449, 0.345154345035553, 0.6752734184265137, 0.5681418180465698, 0.3093763589859009, 0.9965211153030396, 0.9999980330467224, 0.3314661979675293, 0.5324736833572388, 0.31352508068084717, 0.35292088985443115, 0.6175236701965332, 0.7703756093978882, 0.9880334734916687, 0.7674812078475952, 0.3150567412376404, 0.3272002339363098, 0.581548273563385, 0.4758840799331665, 0.9495258927345276, 0.4930107593536377, 0.9779250621795654, 0.9875051975250244, 0.80687415599823, 0.635479211807251, 0.5945831537246704, 0.313957154750824, 0.3043179512023926, 0.30595147609710693, 0.9968533515930176, 0.301356703042984, 0.554725170135498, 0.9002101421356201, 0.9929699897766113, 0.613275945186615, 0.9383182525634766, 0.9734548330307007, 0.3037637770175934, 0.6631838083267212, 0.6650695204734802, 0.4734337329864502, 0.41441547870635986, 0.7581296563148499, 0.35966187715530396, 0.3364078402519226, 0.8283023834228516]
Runs: 0, Training fold:0
AUC =  0.7678004535147392
epoch= 0    train_loss = 3.394300    bag_loss = 0.653809    mse_loss = 1.293608 train_acc=0.641026    test_loss = 3.151682    test_acc=0.649485
epoch= 1    train_loss = 3.193706    bag_loss = 0.604476    mse_loss = 1.282667 train_acc=0.641026    test_loss = 2.979746    test_acc=0.649485
epoch= 2    train_loss = 3.034194    bag_loss = 0.579198    mse_loss = 1.263297 train_acc=0.641026    test_loss = 2.839598    test_acc=0.649485
epoch= 3    train_loss = 2.896218    bag_loss = 0.566161    mse_loss = 1.233629 train_acc=0.641026    test_loss = 2.711419    test_acc=0.649485
epoch= 4    train_loss = 2.772117    bag_loss = 0.556807    mse_loss = 1.198836 train_acc=0.641026    test_loss = 2.596861    test_acc=0.649485
epoch= 5    train_loss = 2.666146    bag_loss = 0.548762    mse_loss = 1.169716 train_acc=0.641026    test_loss = 2.500134    test_acc=0.659794
epoch= 6    train_loss = 2.577213    bag_loss = 0.541679    mse_loss = 1.147905 train_acc=0.676923    test_loss = 2.418849    test_acc=0.670103
epoch= 7    train_loss = 2.501746    bag_loss = 0.535816    mse_loss = 1.130729 train_acc=0.692308    test_loss = 2.348726    test_acc=0.670103
epoch= 8    train_loss = 2.436089    bag_loss = 0.530208    mse_loss = 1.116448 train_acc=0.707692    test_loss = 2.287451    test_acc=0.690722
epoch= 9    train_loss = 2.377846    bag_loss = 0.525411    mse_loss = 1.102780 train_acc=0.723077    test_loss = 2.232304    test_acc=0.701031
epoch= 10    train_loss = 2.324988    bag_loss = 0.519854    mse_loss = 1.090019 train_acc=0.738462    test_loss = 2.182482    test_acc=0.690722
epoch= 11    train_loss = 2.276456    bag_loss = 0.514327    mse_loss = 1.076885 train_acc=0.758974    test_loss = 2.136543    test_acc=0.690722
epoch= 12    train_loss = 2.231449    bag_loss = 0.508557    mse_loss = 1.063368 train_acc=0.769231    test_loss = 2.095299    test_acc=0.690722
epoch= 13    train_loss = 2.189328    bag_loss = 0.502193    mse_loss = 1.049823 train_acc=0.769231    test_loss = 2.059058    test_acc=0.711340
epoch= 14    train_loss = 2.150016    bag_loss = 0.495719    mse_loss = 1.036256 train_acc=0.769231    test_loss = 2.027256    test_acc=0.721649
epoch= 15    train_loss = 2.112200    bag_loss = 0.488899    mse_loss = 1.021976 train_acc=0.774359    test_loss = 1.998116    test_acc=0.721649
epoch= 16    train_loss = 2.076343    bag_loss = 0.482745    mse_loss = 1.006719 train_acc=0.789744    test_loss = 1.971325    test_acc=0.721649
epoch= 17    train_loss = 2.042525    bag_loss = 0.477072    mse_loss = 0.991144 train_acc=0.789744    test_loss = 1.947601    test_acc=0.721649
epoch= 18    train_loss = 2.010888    bag_loss = 0.471635    mse_loss = 0.975993 train_acc=0.779487    test_loss = 1.926964    test_acc=0.721649
epoch= 19    train_loss = 1.981813    bag_loss = 0.466638    mse_loss = 0.961689 train_acc=0.784615    test_loss = 1.909114    test_acc=0.711340
epoch= 20    train_loss = 1.955679    bag_loss = 0.461921    mse_loss = 0.949026 train_acc=0.794872    test_loss = 1.893625    test_acc=0.711340
epoch= 21    train_loss = 1.931973    bag_loss = 0.457483    mse_loss = 0.937731 train_acc=0.794872    test_loss = 1.879689    test_acc=0.711340
epoch= 22    train_loss = 1.909698    bag_loss = 0.453058    mse_loss = 0.927200 train_acc=0.800000    test_loss = 1.866979    test_acc=0.731959
epoch= 23    train_loss = 1.888445    bag_loss = 0.448815    mse_loss = 0.916972 train_acc=0.805128    test_loss = 1.856305    test_acc=0.721649
epoch= 24    train_loss = 1.869233    bag_loss = 0.445616    mse_loss = 0.907274 train_acc=0.805128    test_loss = 1.845338    test_acc=0.731959
epoch= 25    train_loss = 1.849555    bag_loss = 0.441342    mse_loss = 0.897772 train_acc=0.815385    test_loss = 1.836186    test_acc=0.731959
epoch= 26    train_loss = 1.831185    bag_loss = 0.437926    mse_loss = 0.888345 train_acc=0.825641    test_loss = 1.826651    test_acc=0.731959
epoch= 27    train_loss = 1.813260    bag_loss = 0.434059    mse_loss = 0.879547 train_acc=0.825641    test_loss = 1.818517    test_acc=0.731959
epoch= 28    train_loss = 1.796628    bag_loss = 0.430451    mse_loss = 0.871594 train_acc=0.820513    test_loss = 1.811106    test_acc=0.752577
epoch= 29    train_loss = 1.781016    bag_loss = 0.426560    mse_loss = 0.864874 train_acc=0.820513    test_loss = 1.804877    test_acc=0.752577
epoch= 30    train_loss = 1.766798    bag_loss = 0.422768    mse_loss = 0.859395 train_acc=0.820513    test_loss = 1.800421    test_acc=0.752577
epoch= 31    train_loss = 1.754442    bag_loss = 0.419619    mse_loss = 0.855093 train_acc=0.815385    test_loss = 1.796307    test_acc=0.752577
epoch= 32    train_loss = 1.743125    bag_loss = 0.416446    mse_loss = 0.851796 train_acc=0.815385    test_loss = 1.792678    test_acc=0.752577
epoch= 33    train_loss = 1.732476    bag_loss = 0.413218    mse_loss = 0.849137 train_acc=0.815385    test_loss = 1.790631    test_acc=0.742268
epoch= 34    train_loss = 1.722269    bag_loss = 0.409662    mse_loss = 0.847148 train_acc=0.815385    test_loss = 1.789477    test_acc=0.731959
epoch= 35    train_loss = 1.712804    bag_loss = 0.406345    mse_loss = 0.845554 train_acc=0.815385    test_loss = 1.789408    test_acc=0.711340
epoch= 36    train_loss = 1.703547    bag_loss = 0.402757    mse_loss = 0.844278 train_acc=0.815385    test_loss = 1.789100    test_acc=0.711340
epoch= 37    train_loss = 1.695015    bag_loss = 0.399559    mse_loss = 0.843182 train_acc=0.835897    test_loss = 1.788485    test_acc=0.701031
epoch= 38    train_loss = 1.686280    bag_loss = 0.395844    mse_loss = 0.842237 train_acc=0.835897    test_loss = 1.789606    test_acc=0.701031
epoch= 39    train_loss = 1.677993    bag_loss = 0.392252    mse_loss = 0.841448 train_acc=0.841026    test_loss = 1.789794    test_acc=0.701031
epoch= 40    train_loss = 1.669605    bag_loss = 0.388282    mse_loss = 0.840760 train_acc=0.841026    test_loss = 1.790737    test_acc=0.690722
epoch= 41    train_loss = 1.662162    bag_loss = 0.385064    mse_loss = 0.840096 train_acc=0.841026    test_loss = 1.791948    test_acc=0.690722
epoch= 42    train_loss = 1.654688    bag_loss = 0.381617    mse_loss = 0.839480 train_acc=0.841026    test_loss = 1.792750    test_acc=0.680412
epoch= 43    train_loss = 1.647840    bag_loss = 0.378603    mse_loss = 0.838909 train_acc=0.841026    test_loss = 1.794731    test_acc=0.680412
epoch= 44    train_loss = 1.640243    bag_loss = 0.374639    mse_loss = 0.838372 train_acc=0.841026    test_loss = 1.796041    test_acc=0.670103
epoch= 45    train_loss = 1.633252    bag_loss = 0.371190    mse_loss = 0.837783 train_acc=0.841026    test_loss = 1.796902    test_acc=0.659794
epoch= 46    train_loss = 1.627012    bag_loss = 0.368310    mse_loss = 0.837250 train_acc=0.841026    test_loss = 1.797073    test_acc=0.659794
epoch= 47    train_loss = 1.620087    bag_loss = 0.364659    mse_loss = 0.836672 train_acc=0.846154    test_loss = 1.799350    test_acc=0.659794
epoch= 48    train_loss = 1.613595    bag_loss = 0.361375    mse_loss = 0.836054 train_acc=0.851282    test_loss = 1.801394    test_acc=0.659794
epoch= 49    train_loss = 1.607430    bag_loss = 0.358343    mse_loss = 0.835397 train_acc=0.851282    test_loss = 1.803468    test_acc=0.659794
epoch= 50    train_loss = 1.601063    bag_loss = 0.354932    mse_loss = 0.834822 train_acc=0.851282    test_loss = 1.804322    test_acc=0.649485
epoch= 51    train_loss = 1.594794    bag_loss = 0.351576    mse_loss = 0.834162 train_acc=0.851282    test_loss = 1.807382    test_acc=0.639175
epoch= 52    train_loss = 1.589083    bag_loss = 0.348682    mse_loss = 0.833511 train_acc=0.856410    test_loss = 1.808726    test_acc=0.639175
epoch= 53    train_loss = 1.582916    bag_loss = 0.345171    mse_loss = 0.832932 train_acc=0.861538    test_loss = 1.809769    test_acc=0.639175
epoch= 54    train_loss = 1.576945    bag_loss = 0.341830    mse_loss = 0.832320 train_acc=0.861538    test_loss = 1.812758    test_acc=0.639175
epoch= 55    train_loss = 1.571339    bag_loss = 0.338766    mse_loss = 0.831720 train_acc=0.861538    test_loss = 1.813045    test_acc=0.649485
epoch= 56    train_loss = 1.565499    bag_loss = 0.335371    mse_loss = 0.831106 train_acc=0.866667    test_loss = 1.817342    test_acc=0.659794
epoch= 57    train_loss = 1.559466    bag_loss = 0.331680    mse_loss = 0.830527 train_acc=0.871795    test_loss = 1.821027    test_acc=0.659794
epoch= 58    train_loss = 1.553878    bag_loss = 0.328419    mse_loss = 0.829888 train_acc=0.876923    test_loss = 1.821867    test_acc=0.670103
epoch= 59    train_loss = 1.548154    bag_loss = 0.324905    mse_loss = 0.829294 train_acc=0.887179    test_loss = 1.824290    test_acc=0.670103
epoch= 60    train_loss = 1.542968    bag_loss = 0.321917    mse_loss = 0.828652 train_acc=0.892308    test_loss = 1.828425    test_acc=0.670103
epoch= 61    train_loss = 1.537886    bag_loss = 0.318925    mse_loss = 0.828072 train_acc=0.892308    test_loss = 1.830671    test_acc=0.680412
epoch= 62    train_loss = 1.531662    bag_loss = 0.314771    mse_loss = 0.827435 train_acc=0.892308    test_loss = 1.834789    test_acc=0.670103
epoch= 63    train_loss = 1.526346    bag_loss = 0.311466    mse_loss = 0.826818 train_acc=0.892308    test_loss = 1.836633    test_acc=0.680412
epoch= 64    train_loss = 1.520854    bag_loss = 0.307932    mse_loss = 0.826180 train_acc=0.892308    test_loss = 1.839144    test_acc=0.670103
epoch= 65    train_loss = 1.515361    bag_loss = 0.304324    mse_loss = 0.825560 train_acc=0.892308    test_loss = 1.843972    test_acc=0.670103
epoch= 66    train_loss = 1.510060    bag_loss = 0.300936    mse_loss = 0.824872 train_acc=0.892308    test_loss = 1.847566    test_acc=0.670103
epoch= 67    train_loss = 1.504184    bag_loss = 0.296953    mse_loss = 0.824136 train_acc=0.892308    test_loss = 1.851958    test_acc=0.680412
epoch= 68    train_loss = 1.498845    bag_loss = 0.293418    mse_loss = 0.823429 train_acc=0.897436    test_loss = 1.856268    test_acc=0.680412
epoch= 69    train_loss = 1.492968    bag_loss = 0.289292    mse_loss = 0.822670 train_acc=0.907692    test_loss = 1.863915    test_acc=0.680412
epoch= 70    train_loss = 1.487667    bag_loss = 0.285770    mse_loss = 0.821821 train_acc=0.917949    test_loss = 1.868220    test_acc=0.690722
epoch= 71    train_loss = 1.482392    bag_loss = 0.282213    mse_loss = 0.821008 train_acc=0.923077    test_loss = 1.873795    test_acc=0.701031
epoch= 72    train_loss = 1.476031    bag_loss = 0.277458    mse_loss = 0.820245 train_acc=0.928205    test_loss = 1.880682    test_acc=0.690722
epoch= 73    train_loss = 1.471574    bag_loss = 0.274631    mse_loss = 0.819441 train_acc=0.923077    test_loss = 1.884473    test_acc=0.690722
epoch= 74    train_loss = 1.465958    bag_loss = 0.270592    mse_loss = 0.818610 train_acc=0.928205    test_loss = 1.892428    test_acc=0.680412
epoch= 75    train_loss = 1.460220    bag_loss = 0.266385    mse_loss = 0.817790 train_acc=0.928205    test_loss = 1.899666    test_acc=0.680412
epoch= 76    train_loss = 1.455744    bag_loss = 0.263484    mse_loss = 0.816912 train_acc=0.923077    test_loss = 1.906433    test_acc=0.680412
epoch= 77    train_loss = 1.450480    bag_loss = 0.259693    mse_loss = 0.816038 train_acc=0.928205    test_loss = 1.912622    test_acc=0.680412
epoch= 78    train_loss = 1.445237    bag_loss = 0.255870    mse_loss = 0.815183 train_acc=0.933333    test_loss = 1.922809    test_acc=0.680412
epoch= 79    train_loss = 1.440579    bag_loss = 0.252644    mse_loss = 0.814313 train_acc=0.933333    test_loss = 1.927356    test_acc=0.690722
epoch= 80    train_loss = 1.434576    bag_loss = 0.247878    mse_loss = 0.813536 train_acc=0.933333    test_loss = 1.938415    test_acc=0.690722
epoch= 81    train_loss = 1.430218    bag_loss = 0.244811    mse_loss = 0.812664 train_acc=0.933333    test_loss = 1.948174    test_acc=0.690722
epoch= 82    train_loss = 1.425345    bag_loss = 0.241126    mse_loss = 0.811851 train_acc=0.933333    test_loss = 1.952632    test_acc=0.701031
epoch= 83    train_loss = 1.420464    bag_loss = 0.237387    mse_loss = 0.811050 train_acc=0.933333    test_loss = 1.965059    test_acc=0.701031
epoch= 84    train_loss = 1.413918    bag_loss = 0.231993    mse_loss = 0.810165 train_acc=0.933333    test_loss = 1.983155    test_acc=0.690722
epoch= 85    train_loss = 1.407836    bag_loss = 0.226956    mse_loss = 0.809375 train_acc=0.933333    test_loss = 2.004160    test_acc=0.711340
epoch= 86    train_loss = 1.402735    bag_loss = 0.222832    mse_loss = 0.808612 train_acc=0.933333    test_loss = 2.019130    test_acc=0.711340
epoch= 87    train_loss = 1.397409    bag_loss = 0.218456    mse_loss = 0.807835 train_acc=0.938462    test_loss = 2.029492    test_acc=0.701031
epoch= 88    train_loss = 1.391740    bag_loss = 0.213703    mse_loss = 0.807041 train_acc=0.943590    test_loss = 2.050324    test_acc=0.701031
epoch= 89    train_loss = 1.386288    bag_loss = 0.209119    mse_loss = 0.806303 train_acc=0.943590    test_loss = 2.055850    test_acc=0.701031
epoch= 90    train_loss = 1.380621    bag_loss = 0.204295    mse_loss = 0.805597 train_acc=0.948718    test_loss = 2.082346    test_acc=0.701031
epoch= 91    train_loss = 1.376369    bag_loss = 0.200945    mse_loss = 0.804822 train_acc=0.953846    test_loss = 2.092266    test_acc=0.701031
epoch= 92    train_loss = 1.371721    bag_loss = 0.197144    mse_loss = 0.804077 train_acc=0.958974    test_loss = 2.105576    test_acc=0.701031
epoch= 93    train_loss = 1.366464    bag_loss = 0.192693    mse_loss = 0.803366 train_acc=0.958974    test_loss = 2.119944    test_acc=0.701031
epoch= 94    train_loss = 1.361463    bag_loss = 0.188480    mse_loss = 0.802683 train_acc=0.958974    test_loss = 2.146193    test_acc=0.701031
epoch= 95    train_loss = 1.356568    bag_loss = 0.184329    mse_loss = 0.802000 train_acc=0.958974    test_loss = 2.150220    test_acc=0.701031
epoch= 96    train_loss = 1.351759    bag_loss = 0.180383    mse_loss = 0.801151 train_acc=0.958974    test_loss = 2.185974    test_acc=0.701031
epoch= 97    train_loss = 1.349813    bag_loss = 0.179165    mse_loss = 0.800473 train_acc=0.958974    test_loss = 2.176503    test_acc=0.711340
epoch= 98    train_loss = 1.342161    bag_loss = 0.172213    mse_loss = 0.799762 train_acc=0.958974    test_loss = 2.214578    test_acc=0.701031
[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
[0.14701056480407715, 0.9232296943664551, 0.9977596998214722, 0.9048402905464172, 0.9770001769065857, 0.06220880150794983, 0.7856773138046265, 0.9895037412643433, 0.9937950968742371, 0.8721131086349487, 0.5786939859390259, 0.4790688157081604, 0.9995380640029907, 0.6340773105621338, 0.08284136652946472, 0.9281066656112671, 0.9685125350952148, 0.9998456835746765, 0.5435763001441956, 0.9996771812438965, 0.9996969699859619, 0.8693135976791382, 0.07801201939582825, 0.9853162169456482, 0.9855618476867676, 0.9998500943183899, 0.6669122576713562, 0.9999719262123108, 0.2529086470603943, 0.9436872005462646, 0.9967971444129944, 0.9996703267097473, 0.7393660545349121, 0.11002081632614136, 0.9989091157913208, 0.0913219153881073, 0.9961466193199158, 0.8963134288787842, 0.8623532056808472, 0.9995863437652588, 0.19620200991630554, 0.3140820562839508, 0.8917776346206665, 0.9969160556793213, 0.9969550371170044, 0.9331615567207336, 0.9995401501655579, 0.049813687801361084, 0.6269738078117371, 0.9996086359024048, 0.11931577324867249, 0.6202791333198547, 0.7570472359657288, 0.9218007326126099, 0.9942795038223267, 0.06484732031822205, 0.9998657703399658, 0.9853706359863281, 0.9224017858505249, 0.6463755369186401, 0.9483224749565125, 0.07553711533546448, 0.9960817098617554, 0.999649167060852, 0.9731531143188477, 0.9620022773742676, 0.9902670383453369, 0.9930325746536255, 0.028174400329589844, 0.5621745586395264, 0.4030427634716034, 0.9941273331642151, 0.9947301149368286, 0.8420822620391846, 0.9255822896957397, 0.6595910787582397, 0.991081714630127, 0.05228853225708008, 0.9508534669876099, 0.9093050956726074, 0.9814541935920715, 0.6735351085662842, 0.9939669966697693, 0.9284539222717285, 0.08508381247520447, 0.15767356753349304, 0.9502238631248474, 0.9725576043128967, 0.5651071667671204, 0.07657566666603088, 0.8981806039810181, 0.9970199465751648, 0.9999986886978149, 0.04731282591819763, 0.9884529709815979, 0.8128077387809753, 0.9792356491088867]
epoch= 99    train_loss = 1.338144    bag_loss = 0.169023    mse_loss = 0.799026 train_acc=0.964103    test_loss = 2.228940    test_acc=0.701031
Ground truth: [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], Predicted: [0.14701056480407715, 0.9232296943664551, 0.9977596998214722, 0.9048402905464172, 0.9770001769065857, 0.06220880150794983, 0.7856773138046265, 0.9895037412643433, 0.9937950968742371, 0.8721131086349487, 0.5786939859390259, 0.4790688157081604, 0.9995380640029907, 0.6340773105621338, 0.08284136652946472, 0.9281066656112671, 0.9685125350952148, 0.9998456835746765, 0.5435763001441956, 0.9996771812438965, 0.9996969699859619, 0.8693135976791382, 0.07801201939582825, 0.9853162169456482, 0.9855618476867676, 0.9998500943183899, 0.6669122576713562, 0.9999719262123108, 0.2529086470603943, 0.9436872005462646, 0.9967971444129944, 0.9996703267097473, 0.7393660545349121, 0.11002081632614136, 0.9989091157913208, 0.0913219153881073, 0.9961466193199158, 0.8963134288787842, 0.8623532056808472, 0.9995863437652588, 0.19620200991630554, 0.3140820562839508, 0.8917776346206665, 0.9969160556793213, 0.9969550371170044, 0.9331615567207336, 0.9995401501655579, 0.049813687801361084, 0.6269738078117371, 0.9996086359024048, 0.11931577324867249, 0.6202791333198547, 0.7570472359657288, 0.9218007326126099, 0.9942795038223267, 0.06484732031822205, 0.9998657703399658, 0.9853706359863281, 0.9224017858505249, 0.6463755369186401, 0.9483224749565125, 0.07553711533546448, 0.9960817098617554, 0.999649167060852, 0.9731531143188477, 0.9620022773742676, 0.9902670383453369, 0.9930325746536255, 0.028174400329589844, 0.5621745586395264, 0.4030427634716034, 0.9941273331642151, 0.9947301149368286, 0.8420822620391846, 0.9255822896957397, 0.6595910787582397, 0.991081714630127, 0.05228853225708008, 0.9508534669876099, 0.9093050956726074, 0.9814541935920715, 0.6735351085662842, 0.9939669966697693, 0.9284539222717285, 0.08508381247520447, 0.15767356753349304, 0.9502238631248474, 0.9725576043128967, 0.5651071667671204, 0.07657566666603088, 0.8981806039810181, 0.9970199465751648, 0.9999986886978149, 0.04731282591819763, 0.9884529709815979, 0.8128077387809753, 0.9792356491088867]
Runs: 0, Training fold:1
AUC =  0.6316526610644257
epoch= 0    train_loss = 3.408181    bag_loss = 0.676302    mse_loss = 1.256975 train_acc=0.625641    test_loss = 3.267910    test_acc=0.639175
epoch= 1    train_loss = 3.196424    bag_loss = 0.629402    mse_loss = 1.249785 train_acc=0.646154    test_loss = 3.072839    test_acc=0.639175
epoch= 2    train_loss = 3.017071    bag_loss = 0.589527    mse_loss = 1.235818 train_acc=0.646154    test_loss = 2.931148    test_acc=0.639175
epoch= 3    train_loss = 2.869702    bag_loss = 0.572595    mse_loss = 1.207871 train_acc=0.646154    test_loss = 2.805996    test_acc=0.639175
epoch= 4    train_loss = 2.728666    bag_loss = 0.563731    mse_loss = 1.158968 train_acc=0.646154    test_loss = 2.681738    test_acc=0.639175
epoch= 5    train_loss = 2.590492    bag_loss = 0.556485    mse_loss = 1.095223 train_acc=0.646154    test_loss = 2.571432    test_acc=0.639175
epoch= 6    train_loss = 2.472804    bag_loss = 0.548231    mse_loss = 1.041862 train_acc=0.692308    test_loss = 2.480945    test_acc=0.680412
epoch= 7    train_loss = 2.382455    bag_loss = 0.538606    mse_loss = 1.010008 train_acc=0.717949    test_loss = 2.407109    test_acc=0.690722
epoch= 8    train_loss = 2.311281    bag_loss = 0.527615    mse_loss = 0.993174 train_acc=0.728205    test_loss = 2.344710    test_acc=0.701031
epoch= 9    train_loss = 2.251556    bag_loss = 0.516838    mse_loss = 0.982543 train_acc=0.748718    test_loss = 2.291470    test_acc=0.731959
epoch= 10    train_loss = 2.200055    bag_loss = 0.507227    mse_loss = 0.974072 train_acc=0.753846    test_loss = 2.246379    test_acc=0.742268
epoch= 11    train_loss = 2.155250    bag_loss = 0.499175    mse_loss = 0.966166 train_acc=0.738462    test_loss = 2.206991    test_acc=0.752577
epoch= 12    train_loss = 2.116499    bag_loss = 0.492321    mse_loss = 0.959226 train_acc=0.743590    test_loss = 2.175409    test_acc=0.742268
epoch= 13    train_loss = 2.082502    bag_loss = 0.485924    mse_loss = 0.953385 train_acc=0.738462    test_loss = 2.147125    test_acc=0.752577
epoch= 14    train_loss = 2.052429    bag_loss = 0.480828    mse_loss = 0.947390 train_acc=0.769231    test_loss = 2.124166    test_acc=0.752577
epoch= 15    train_loss = 2.025008    bag_loss = 0.475172    mse_loss = 0.942399 train_acc=0.774359    test_loss = 2.101594    test_acc=0.752577
epoch= 16    train_loss = 2.000069    bag_loss = 0.470969    mse_loss = 0.936440 train_acc=0.774359    test_loss = 2.082155    test_acc=0.742268
epoch= 17    train_loss = 1.976285    bag_loss = 0.465737    mse_loss = 0.930956 train_acc=0.784615    test_loss = 2.064029    test_acc=0.731959
epoch= 18    train_loss = 1.954317    bag_loss = 0.461675    mse_loss = 0.924554 train_acc=0.779487    test_loss = 2.048679    test_acc=0.731959
epoch= 19    train_loss = 1.933271    bag_loss = 0.457086    mse_loss = 0.918438 train_acc=0.784615    test_loss = 2.032841    test_acc=0.721649
epoch= 20    train_loss = 1.913611    bag_loss = 0.453459    mse_loss = 0.911751 train_acc=0.794872    test_loss = 2.019902    test_acc=0.731959
epoch= 21    train_loss = 1.895068    bag_loss = 0.449341    mse_loss = 0.906021 train_acc=0.805128    test_loss = 2.005055    test_acc=0.731959
epoch= 22    train_loss = 1.877736    bag_loss = 0.445662    mse_loss = 0.900311 train_acc=0.815385    test_loss = 1.995258    test_acc=0.742268
epoch= 23    train_loss = 1.860566    bag_loss = 0.441521    mse_loss = 0.894697 train_acc=0.815385    test_loss = 1.982144    test_acc=0.742268
epoch= 24    train_loss = 1.844757    bag_loss = 0.437761    mse_loss = 0.889524 train_acc=0.815385    test_loss = 1.974274    test_acc=0.742268
epoch= 25    train_loss = 1.829283    bag_loss = 0.433827    mse_loss = 0.884466 train_acc=0.820513    test_loss = 1.963017    test_acc=0.742268
epoch= 26    train_loss = 1.814901    bag_loss = 0.430137    mse_loss = 0.879755 train_acc=0.825641    test_loss = 1.957654    test_acc=0.742268
epoch= 27    train_loss = 1.800671    bag_loss = 0.425724    mse_loss = 0.875646 train_acc=0.825641    test_loss = 1.950318    test_acc=0.731959
epoch= 28    train_loss = 1.788138    bag_loss = 0.422269    mse_loss = 0.871897 train_acc=0.825641    test_loss = 1.945263    test_acc=0.731959
epoch= 29    train_loss = 1.775472    bag_loss = 0.418141    mse_loss = 0.868510 train_acc=0.830769    test_loss = 1.938687    test_acc=0.731959
epoch= 30    train_loss = 1.764494    bag_loss = 0.414785    mse_loss = 0.865757 train_acc=0.830769    test_loss = 1.935563    test_acc=0.731959
epoch= 31    train_loss = 1.753152    bag_loss = 0.410675    mse_loss = 0.863215 train_acc=0.835897    test_loss = 1.930083    test_acc=0.731959
epoch= 32    train_loss = 1.742715    bag_loss = 0.407040    mse_loss = 0.860827 train_acc=0.841026    test_loss = 1.927695    test_acc=0.731959
epoch= 33    train_loss = 1.730121    bag_loss = 0.402647    mse_loss = 0.856849 train_acc=0.841026    test_loss = 1.923180    test_acc=0.731959
epoch= 34    train_loss = 1.719975    bag_loss = 0.398674    mse_loss = 0.854504 train_acc=0.846154    test_loss = 1.922053    test_acc=0.731959
epoch= 35    train_loss = 1.710244    bag_loss = 0.394320    mse_loss = 0.852823 train_acc=0.841026    test_loss = 1.919092    test_acc=0.742268
epoch= 36    train_loss = 1.701534    bag_loss = 0.390533    mse_loss = 0.851421 train_acc=0.846154    test_loss = 1.919455    test_acc=0.742268
epoch= 37    train_loss = 1.692315    bag_loss = 0.385990    mse_loss = 0.850120 train_acc=0.846154    test_loss = 1.919031    test_acc=0.731959
epoch= 38    train_loss = 1.684185    bag_loss = 0.382454    mse_loss = 0.848667 train_acc=0.851282    test_loss = 1.920361    test_acc=0.731959
epoch= 39    train_loss = 1.674791    bag_loss = 0.376949    mse_loss = 0.847832 train_acc=0.851282    test_loss = 1.920591    test_acc=0.742268
epoch= 40    train_loss = 1.666100    bag_loss = 0.371953    mse_loss = 0.846953 train_acc=0.851282    test_loss = 1.923396    test_acc=0.731959
epoch= 41    train_loss = 1.657479    bag_loss = 0.367282    mse_loss = 0.845708 train_acc=0.851282    test_loss = 1.924592    test_acc=0.731959
epoch= 42    train_loss = 1.649572    bag_loss = 0.362253    mse_loss = 0.845422 train_acc=0.851282    test_loss = 1.928961    test_acc=0.731959
epoch= 43    train_loss = 1.641073    bag_loss = 0.357329    mse_loss = 0.844315 train_acc=0.856410    test_loss = 1.928155    test_acc=0.742268
epoch= 44    train_loss = 1.634858    bag_loss = 0.353398    mse_loss = 0.844259 train_acc=0.861538    test_loss = 1.935873    test_acc=0.731959
epoch= 45    train_loss = 1.625623    bag_loss = 0.347419    mse_loss = 0.843194 train_acc=0.866667    test_loss = 1.939445    test_acc=0.742268
epoch= 46    train_loss = 1.617384    bag_loss = 0.341224    mse_loss = 0.843295 train_acc=0.871795    test_loss = 1.945943    test_acc=0.731959
epoch= 47    train_loss = 1.609958    bag_loss = 0.336825    mse_loss = 0.842270 train_acc=0.871795    test_loss = 1.949376    test_acc=0.731959
epoch= 48    train_loss = 1.602005    bag_loss = 0.331113    mse_loss = 0.841947 train_acc=0.871795    test_loss = 1.955305    test_acc=0.731959
epoch= 49    train_loss = 1.594022    bag_loss = 0.325773    mse_loss = 0.841088 train_acc=0.871795    test_loss = 1.958991    test_acc=0.742268
epoch= 50    train_loss = 1.585796    bag_loss = 0.320790    mse_loss = 0.839509 train_acc=0.871795    test_loss = 1.964670    test_acc=0.721649
epoch= 51    train_loss = 1.577160    bag_loss = 0.314929    mse_loss = 0.838224 train_acc=0.871795    test_loss = 1.970375    test_acc=0.721649
epoch= 52    train_loss = 1.569921    bag_loss = 0.309476    mse_loss = 0.837853 train_acc=0.876923    test_loss = 1.979024    test_acc=0.721649
epoch= 53    train_loss = 1.562240    bag_loss = 0.304229    mse_loss = 0.836804 train_acc=0.882051    test_loss = 1.984612    test_acc=0.721649
epoch= 54    train_loss = 1.555389    bag_loss = 0.298397    mse_loss = 0.837185 train_acc=0.892308    test_loss = 1.994842    test_acc=0.721649
epoch= 55    train_loss = 1.547647    bag_loss = 0.293115    mse_loss = 0.836047 train_acc=0.897436    test_loss = 2.000466    test_acc=0.721649
epoch= 56    train_loss = 1.540629    bag_loss = 0.287122    mse_loss = 0.836237 train_acc=0.897436    test_loss = 2.010879    test_acc=0.721649
epoch= 57    train_loss = 1.533331    bag_loss = 0.281682    mse_loss = 0.835547 train_acc=0.902564    test_loss = 2.020998    test_acc=0.721649
epoch= 58    train_loss = 1.526404    bag_loss = 0.276001    mse_loss = 0.835454 train_acc=0.907692    test_loss = 2.029973    test_acc=0.701031
epoch= 59    train_loss = 1.519890    bag_loss = 0.270876    mse_loss = 0.835092 train_acc=0.907692    test_loss = 2.040403    test_acc=0.690722
epoch= 60    train_loss = 1.512574    bag_loss = 0.264445    mse_loss = 0.835174 train_acc=0.917949    test_loss = 2.051289    test_acc=0.701031
epoch= 61    train_loss = 1.504771    bag_loss = 0.258166    mse_loss = 0.834557 train_acc=0.917949    test_loss = 2.064532    test_acc=0.690722
epoch= 62    train_loss = 1.498070    bag_loss = 0.251831    mse_loss = 0.835050 train_acc=0.928205    test_loss = 2.074155    test_acc=0.680412
epoch= 63    train_loss = 1.489720    bag_loss = 0.245933    mse_loss = 0.833343 train_acc=0.933333    test_loss = 2.086265    test_acc=0.680412
epoch= 64    train_loss = 1.482874    bag_loss = 0.239530    mse_loss = 0.833612 train_acc=0.933333    test_loss = 2.102073    test_acc=0.680412
epoch= 65    train_loss = 1.474476    bag_loss = 0.232746    mse_loss = 0.832673 train_acc=0.943590    test_loss = 2.114643    test_acc=0.680412
epoch= 66    train_loss = 1.468383    bag_loss = 0.226914    mse_loss = 0.833091 train_acc=0.938462    test_loss = 2.129302    test_acc=0.680412
epoch= 67    train_loss = 1.461130    bag_loss = 0.220860    mse_loss = 0.832553 train_acc=0.943590    test_loss = 2.142219    test_acc=0.680412
epoch= 68    train_loss = 1.453591    bag_loss = 0.214197    mse_loss = 0.832336 train_acc=0.943590    test_loss = 2.159134    test_acc=0.680412
epoch= 69    train_loss = 1.447494    bag_loss = 0.209400    mse_loss = 0.831681 train_acc=0.948718    test_loss = 2.169589    test_acc=0.680412
epoch= 70    train_loss = 1.439074    bag_loss = 0.203849    mse_loss = 0.829367 train_acc=0.958974    test_loss = 2.185222    test_acc=0.680412
epoch= 71    train_loss = 1.432246    bag_loss = 0.198177    mse_loss = 0.828735 train_acc=0.958974    test_loss = 2.203590    test_acc=0.680412
epoch= 72    train_loss = 1.426179    bag_loss = 0.193294    mse_loss = 0.828102 train_acc=0.964103    test_loss = 2.212092    test_acc=0.680412
epoch= 73    train_loss = 1.421056    bag_loss = 0.188806    mse_loss = 0.828022 train_acc=0.964103    test_loss = 2.237386    test_acc=0.680412
epoch= 74    train_loss = 1.414662    bag_loss = 0.183761    mse_loss = 0.827309 train_acc=0.964103    test_loss = 2.241785    test_acc=0.680412
epoch= 75    train_loss = 1.409033    bag_loss = 0.179596    mse_loss = 0.826429 train_acc=0.964103    test_loss = 2.265757    test_acc=0.680412
epoch= 76    train_loss = 1.402334    bag_loss = 0.174246    mse_loss = 0.825642 train_acc=0.969231    test_loss = 2.276708    test_acc=0.680412
epoch= 77    train_loss = 1.396293    bag_loss = 0.169670    mse_loss = 0.824771 train_acc=0.974359    test_loss = 2.291706    test_acc=0.680412
epoch= 78    train_loss = 1.391287    bag_loss = 0.165847    mse_loss = 0.824129 train_acc=0.974359    test_loss = 2.301091    test_acc=0.680412
epoch= 79    train_loss = 1.386434    bag_loss = 0.161855    mse_loss = 0.823846 train_acc=0.974359    test_loss = 2.325488    test_acc=0.680412
epoch= 80    train_loss = 1.381205    bag_loss = 0.157578    mse_loss = 0.823499 train_acc=0.974359    test_loss = 2.343265    test_acc=0.680412
epoch= 81    train_loss = 1.377969    bag_loss = 0.154941    mse_loss = 0.823495 train_acc=0.974359    test_loss = 2.348484    test_acc=0.680412
epoch= 82    train_loss = 1.371013    bag_loss = 0.148962    mse_loss = 0.823116 train_acc=0.974359    test_loss = 2.373232    test_acc=0.680412
epoch= 83    train_loss = 1.366199    bag_loss = 0.144922    mse_loss = 0.823005 train_acc=0.974359    test_loss = 2.382967    test_acc=0.680412
epoch= 84    train_loss = 1.362939    bag_loss = 0.142551    mse_loss = 0.822809 train_acc=0.974359    test_loss = 2.385738    test_acc=0.680412
epoch= 85    train_loss = 1.358728    bag_loss = 0.139052    mse_loss = 0.822726 train_acc=0.979487    test_loss = 2.411916    test_acc=0.680412
epoch= 86    train_loss = 1.353381    bag_loss = 0.134582    mse_loss = 0.822476 train_acc=0.979487    test_loss = 2.421805    test_acc=0.680412
epoch= 87    train_loss = 1.349551    bag_loss = 0.131588    mse_loss = 0.822335 train_acc=0.979487    test_loss = 2.448484    test_acc=0.690722
epoch= 88    train_loss = 1.345227    bag_loss = 0.128210    mse_loss = 0.822131 train_acc=0.979487    test_loss = 2.442062    test_acc=0.680412
epoch= 89    train_loss = 1.340422    bag_loss = 0.124234    mse_loss = 0.821965 train_acc=0.979487    test_loss = 2.469373    test_acc=0.690722
epoch= 90    train_loss = 1.337461    bag_loss = 0.122093    mse_loss = 0.821899 train_acc=0.979487    test_loss = 2.497255    test_acc=0.690722
epoch= 91    train_loss = 1.333444    bag_loss = 0.118962    mse_loss = 0.821733 train_acc=0.979487    test_loss = 2.500559    test_acc=0.690722
epoch= 92    train_loss = 1.329647    bag_loss = 0.116243    mse_loss = 0.821406 train_acc=0.979487    test_loss = 2.501729    test_acc=0.690722
epoch= 93    train_loss = 1.326161    bag_loss = 0.113491    mse_loss = 0.821424 train_acc=0.979487    test_loss = 2.533965    test_acc=0.690722
epoch= 94    train_loss = 1.321068    bag_loss = 0.109406    mse_loss = 0.821215 train_acc=0.979487    test_loss = 2.544243    test_acc=0.690722
epoch= 95    train_loss = 1.318291    bag_loss = 0.107563    mse_loss = 0.821047 train_acc=0.979487    test_loss = 2.556816    test_acc=0.690722
epoch= 96    train_loss = 1.314291    bag_loss = 0.104432    mse_loss = 0.820934 train_acc=0.979487    test_loss = 2.548269    test_acc=0.690722
epoch= 97    train_loss = 1.310866    bag_loss = 0.102038    mse_loss = 0.820721 train_acc=0.979487    test_loss = 2.574182    test_acc=0.690722
epoch= 98    train_loss = 1.306375    bag_loss = 0.098483    mse_loss = 0.820582 train_acc=0.979487    test_loss = 2.578374    test_acc=0.690722
[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]
[0.9952224493026733, 0.9984602928161621, 0.9998934268951416, 0.01315760612487793, 0.9190062284469604, 0.9673407077789307, 0.9682720899581909, 0.879304826259613, 0.9991269707679749, 0.9905534982681274, 0.9992578625679016, 0.9990172982215881, 0.14465469121932983, 0.3426549434661865, 0.999937891960144, 0.1719105839729309, 0.9942319393157959, 0.9138150215148926, 0.9985155463218689, 0.9922587275505066, 0.753456711769104, 0.04202410578727722, 0.9996961355209351, 0.5386245846748352, 0.9993000030517578, 0.9740976691246033, 0.010433018207550049, 0.9898996353149414, 0.8688278794288635, 0.9998297691345215, 0.9118238687515259, 0.9366773366928101, 0.7926132678985596, 0.8732051849365234, 0.9999788999557495, 0.9826699495315552, 0.0075722336769104, 0.9997836351394653, 0.6550281047821045, 0.8724156022071838, 0.1669618785381317, 0.9998118877410889, 0.9999680519104004, 0.9997288584709167, 0.9999975562095642, 0.8669872283935547, 0.999967098236084, 0.03964361548423767, 0.9998427629470825, 0.9981139302253723, 0.9990880489349365, 0.07131648063659668, 0.16389304399490356, 0.9808803796768188, 0.8768458366394043, 0.9986854791641235, 0.7268210053443909, 0.999611496925354, 0.997408926486969, 0.1357392966747284, 1.0, 0.9940446615219116, 0.9978362917900085, 0.9995192289352417, 0.6654849052429199, 0.9998270273208618, 0.8754827976226807, 0.9854711890220642, 0.5752021074295044, 0.9984161257743835, 0.9999960660934448, 0.003864288330078125, 0.050613224506378174, 0.04914146661758423, 0.9638417959213257, 0.9688727855682373, 0.9999967813491821, 0.780157744884491, 0.003929048776626587, 0.9706168174743652, 0.11337006092071533, 0.07438632845878601, 0.9958000183105469, 0.9997393488883972, 0.9992070198059082, 0.19594451785087585, 0.8270349502563477, 0.9999970197677612, 0.9997016191482544, 0.9564369916915894, 0.9943121671676636, 0.9999454021453857, 0.9895961284637451, 0.005261808633804321, 0.05645632743835449, 0.6006238460540771, 0.7388709187507629]
epoch= 99    train_loss = 1.304397    bag_loss = 0.097346    mse_loss = 0.820517 train_acc=0.979487    test_loss = 2.626847    test_acc=0.690722
Ground truth: [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], Predicted: [0.9952224493026733, 0.9984602928161621, 0.9998934268951416, 0.01315760612487793, 0.9190062284469604, 0.9673407077789307, 0.9682720899581909, 0.879304826259613, 0.9991269707679749, 0.9905534982681274, 0.9992578625679016, 0.9990172982215881, 0.14465469121932983, 0.3426549434661865, 0.999937891960144, 0.1719105839729309, 0.9942319393157959, 0.9138150215148926, 0.9985155463218689, 0.9922587275505066, 0.753456711769104, 0.04202410578727722, 0.9996961355209351, 0.5386245846748352, 0.9993000030517578, 0.9740976691246033, 0.010433018207550049, 0.9898996353149414, 0.8688278794288635, 0.9998297691345215, 0.9118238687515259, 0.9366773366928101, 0.7926132678985596, 0.8732051849365234, 0.9999788999557495, 0.9826699495315552, 0.0075722336769104, 0.9997836351394653, 0.6550281047821045, 0.8724156022071838, 0.1669618785381317, 0.9998118877410889, 0.9999680519104004, 0.9997288584709167, 0.9999975562095642, 0.8669872283935547, 0.999967098236084, 0.03964361548423767, 0.9998427629470825, 0.9981139302253723, 0.9990880489349365, 0.07131648063659668, 0.16389304399490356, 0.9808803796768188, 0.8768458366394043, 0.9986854791641235, 0.7268210053443909, 0.999611496925354, 0.997408926486969, 0.1357392966747284, 1.0, 0.9940446615219116, 0.9978362917900085, 0.9995192289352417, 0.6654849052429199, 0.9998270273208618, 0.8754827976226807, 0.9854711890220642, 0.5752021074295044, 0.9984161257743835, 0.9999960660934448, 0.003864288330078125, 0.050613224506378174, 0.04914146661758423, 0.9638417959213257, 0.9688727855682373, 0.9999967813491821, 0.780157744884491, 0.003929048776626587, 0.9706168174743652, 0.11337006092071533, 0.07438632845878601, 0.9958000183105469, 0.9997393488883972, 0.9992070198059082, 0.19594451785087585, 0.8270349502563477, 0.9999970197677612, 0.9997016191482544, 0.9564369916915894, 0.9943121671676636, 0.9999454021453857, 0.9895961284637451, 0.005261808633804321, 0.05645632743835449, 0.6006238460540771, 0.7388709187507629]
Runs: 0, Training fold:2
AUC =  0.6612903225806451
Mean accuracy =  0.7054141244126516
Acc std =  0.014129902985573602
Mean AUC =  0.6869144790532701
AUC std =  0.0

Process finished with exit code 0

D:\ProgramData\Anaconda3\envs\SSL4MIS\python.exe D:/Desktop/AMINN/main.py
2023-02-10 21:05:56.829921: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-02-10 21:05:56.830031: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-02-10 21:05:58.978835: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-10 21:05:58.979356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2023-02-10 21:05:59.005445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1660 SUPER computeCapability: 7.5
coreClock: 1.785GHz coreCount: 22 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2023-02-10 21:05:59.007688: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-02-10 21:05:59.009687: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2023-02-10 21:05:59.011694: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2023-02-10 21:05:59.015131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2023-02-10 21:05:59.016242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2023-02-10 21:05:59.020026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2023-02-10 21:05:59.022115: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2023-02-10 21:05:59.024134: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2023-02-10 21:05:59.024229: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2023-02-10 21:05:59.024641: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-10 21:05:59.025359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-02-10 21:05:59.025444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]
2023-02-10 21:05:59.025500: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-02-10 21:06:00.426060: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
epoch= 0    train_loss = 3.307213    bag_loss = 0.673272    mse_loss = 1.186212 train_acc=0.644330    test_loss = 3.373746    test_acc=0.642857
epoch= 1    train_loss = 3.105081    bag_loss = 0.641414    mse_loss = 1.175078 train_acc=0.644330    test_loss = 3.177039    test_acc=0.642857
epoch= 2    train_loss = 2.918989    bag_loss = 0.609930    mse_loss = 1.146690 train_acc=0.644330    test_loss = 2.992906    test_acc=0.642857
epoch= 3    train_loss = 2.743404    bag_loss = 0.592238    mse_loss = 1.087535 train_acc=0.654639    test_loss = 2.817784    test_acc=0.663265
epoch= 4    train_loss = 2.586003    bag_loss = 0.580393    mse_loss = 1.020875 train_acc=0.695876    test_loss = 2.664825    test_acc=0.714286
epoch= 5    train_loss = 2.450871    bag_loss = 0.566439    mse_loss = 0.964903 train_acc=0.726804    test_loss = 2.536799    test_acc=0.714286
epoch= 6    train_loss = 2.336552    bag_loss = 0.553540    mse_loss = 0.918075 train_acc=0.711340    test_loss = 2.433406    test_acc=0.704082
epoch= 7    train_loss = 2.248945    bag_loss = 0.547279    mse_loss = 0.883322 train_acc=0.737113    test_loss = 2.355837    test_acc=0.704082
epoch= 8    train_loss = 2.178809    bag_loss = 0.542010    mse_loss = 0.859215 train_acc=0.737113    test_loss = 2.292354    test_acc=0.704082
epoch= 9    train_loss = 2.119399    bag_loss = 0.537375    mse_loss = 0.840229 train_acc=0.737113    test_loss = 2.238800    test_acc=0.704082
epoch= 10    train_loss = 2.068583    bag_loss = 0.533583    mse_loss = 0.824817 train_acc=0.747423    test_loss = 2.193142    test_acc=0.714286
epoch= 11    train_loss = 2.024784    bag_loss = 0.529607    mse_loss = 0.813078 train_acc=0.747423    test_loss = 2.154554    test_acc=0.724490
epoch= 12    train_loss = 1.986998    bag_loss = 0.525864    mse_loss = 0.804029 train_acc=0.752577    test_loss = 2.120958    test_acc=0.724490
epoch= 13    train_loss = 1.952991    bag_loss = 0.522000    mse_loss = 0.796146 train_acc=0.747423    test_loss = 2.091934    test_acc=0.734694
epoch= 14    train_loss = 1.923899    bag_loss = 0.518745    mse_loss = 0.790196 train_acc=0.747423    test_loss = 2.067028    test_acc=0.744898
epoch= 15    train_loss = 1.897672    bag_loss = 0.515421    mse_loss = 0.785148 train_acc=0.752577    test_loss = 2.045509    test_acc=0.744898
epoch= 16    train_loss = 1.874464    bag_loss = 0.512031    mse_loss = 0.781390 train_acc=0.757732    test_loss = 2.026792    test_acc=0.744898
epoch= 17    train_loss = 1.852845    bag_loss = 0.508677    mse_loss = 0.777659 train_acc=0.762887    test_loss = 2.008434    test_acc=0.734694
epoch= 18    train_loss = 1.832481    bag_loss = 0.505424    mse_loss = 0.773686 train_acc=0.773196    test_loss = 1.992574    test_acc=0.744898
epoch= 19    train_loss = 1.814553    bag_loss = 0.502488    mse_loss = 0.770657 train_acc=0.773196    test_loss = 1.978474    test_acc=0.744898
epoch= 20    train_loss = 1.797462    bag_loss = 0.499168    mse_loss = 0.767811 train_acc=0.768041    test_loss = 1.966143    test_acc=0.744898
epoch= 21    train_loss = 1.781832    bag_loss = 0.495930    mse_loss = 0.765423 train_acc=0.778351    test_loss = 1.955355    test_acc=0.744898
epoch= 22    train_loss = 1.767477    bag_loss = 0.492525    mse_loss = 0.763714 train_acc=0.773196    test_loss = 1.945648    test_acc=0.744898
epoch= 23    train_loss = 1.754280    bag_loss = 0.489435    mse_loss = 0.762199 train_acc=0.773196    test_loss = 1.936562    test_acc=0.744898
epoch= 24    train_loss = 1.741658    bag_loss = 0.486120    mse_loss = 0.760882 train_acc=0.778351    test_loss = 1.928293    test_acc=0.744898
epoch= 25    train_loss = 1.729373    bag_loss = 0.482537    mse_loss = 0.759625 train_acc=0.778351    test_loss = 1.920740    test_acc=0.744898
epoch= 26    train_loss = 1.717682    bag_loss = 0.479699    mse_loss = 0.757758 train_acc=0.778351    test_loss = 1.912444    test_acc=0.744898
epoch= 27    train_loss = 1.705022    bag_loss = 0.476718    mse_loss = 0.754602 train_acc=0.773196    test_loss = 1.903835    test_acc=0.765306
epoch= 28    train_loss = 1.693987    bag_loss = 0.473844    mse_loss = 0.752452 train_acc=0.773196    test_loss = 1.897329    test_acc=0.765306
epoch= 29    train_loss = 1.683817    bag_loss = 0.470486    mse_loss = 0.751305 train_acc=0.773196    test_loss = 1.892019    test_acc=0.744898
epoch= 30    train_loss = 1.674362    bag_loss = 0.467295    mse_loss = 0.750393 train_acc=0.773196    test_loss = 1.887284    test_acc=0.744898
epoch= 31    train_loss = 1.665141    bag_loss = 0.463927    mse_loss = 0.749582 train_acc=0.773196    test_loss = 1.882864    test_acc=0.744898
epoch= 32    train_loss = 1.656311    bag_loss = 0.460608    mse_loss = 0.748814 train_acc=0.778351    test_loss = 1.878826    test_acc=0.744898
epoch= 33    train_loss = 1.647404    bag_loss = 0.456866    mse_loss = 0.748111 train_acc=0.793814    test_loss = 1.875153    test_acc=0.744898
epoch= 34    train_loss = 1.639177    bag_loss = 0.453497    mse_loss = 0.747468 train_acc=0.804124    test_loss = 1.871889    test_acc=0.744898
epoch= 35    train_loss = 1.631361    bag_loss = 0.450294    mse_loss = 0.746847 train_acc=0.809278    test_loss = 1.869208    test_acc=0.744898
epoch= 36    train_loss = 1.623532    bag_loss = 0.446775    mse_loss = 0.746308 train_acc=0.804124    test_loss = 1.866476    test_acc=0.734694
epoch= 37    train_loss = 1.615841    bag_loss = 0.443143    mse_loss = 0.745809 train_acc=0.804124    test_loss = 1.864281    test_acc=0.734694
epoch= 38    train_loss = 1.608366    bag_loss = 0.439548    mse_loss = 0.745265 train_acc=0.804124    test_loss = 1.862584    test_acc=0.734694
epoch= 39    train_loss = 1.601124    bag_loss = 0.435988    mse_loss = 0.744754 train_acc=0.804124    test_loss = 1.860759    test_acc=0.734694
epoch= 40    train_loss = 1.593842    bag_loss = 0.432183    mse_loss = 0.744271 train_acc=0.804124    test_loss = 1.859456    test_acc=0.724490
epoch= 41    train_loss = 1.586818    bag_loss = 0.428439    mse_loss = 0.743827 train_acc=0.804124    test_loss = 1.858798    test_acc=0.734694
epoch= 42    train_loss = 1.579716    bag_loss = 0.424486    mse_loss = 0.743372 train_acc=0.804124    test_loss = 1.858549    test_acc=0.734694
epoch= 43    train_loss = 1.573093    bag_loss = 0.420881    mse_loss = 0.742927 train_acc=0.804124    test_loss = 1.858408    test_acc=0.734694
epoch= 44    train_loss = 1.566444    bag_loss = 0.417106    mse_loss = 0.742507 train_acc=0.804124    test_loss = 1.858661    test_acc=0.734694
epoch= 45    train_loss = 1.560180    bag_loss = 0.413565    mse_loss = 0.742111 train_acc=0.804124    test_loss = 1.859849    test_acc=0.734694
epoch= 46    train_loss = 1.553843    bag_loss = 0.409837    mse_loss = 0.741724 train_acc=0.804124    test_loss = 1.859792    test_acc=0.734694
epoch= 47    train_loss = 1.547383    bag_loss = 0.405852    mse_loss = 0.741365 train_acc=0.809278    test_loss = 1.862066    test_acc=0.734694
epoch= 48    train_loss = 1.541544    bag_loss = 0.402410    mse_loss = 0.740982 train_acc=0.814433    test_loss = 1.861779    test_acc=0.724490
epoch= 49    train_loss = 1.535240    bag_loss = 0.398376    mse_loss = 0.740624 train_acc=0.814433    test_loss = 1.863222    test_acc=0.724490
epoch= 50    train_loss = 1.529112    bag_loss = 0.394394    mse_loss = 0.740291 train_acc=0.819588    test_loss = 1.865311    test_acc=0.724490
epoch= 51    train_loss = 1.523445    bag_loss = 0.390840    mse_loss = 0.739919 train_acc=0.819588    test_loss = 1.866129    test_acc=0.724490
epoch= 52    train_loss = 1.517325    bag_loss = 0.386676    mse_loss = 0.739606 train_acc=0.829897    test_loss = 1.868256    test_acc=0.724490
epoch= 53    train_loss = 1.511432    bag_loss = 0.382717    mse_loss = 0.739224 train_acc=0.829897    test_loss = 1.869735    test_acc=0.724490
epoch= 54    train_loss = 1.505271    bag_loss = 0.378384    mse_loss = 0.738864 train_acc=0.829897    test_loss = 1.872417    test_acc=0.714286
epoch= 55    train_loss = 1.499418    bag_loss = 0.374260    mse_loss = 0.738500 train_acc=0.829897    test_loss = 1.874416    test_acc=0.704082
epoch= 56    train_loss = 1.493273    bag_loss = 0.369717    mse_loss = 0.738196 train_acc=0.840206    test_loss = 1.876630    test_acc=0.704082
epoch= 57    train_loss = 1.487513    bag_loss = 0.365562    mse_loss = 0.737779 train_acc=0.840206    test_loss = 1.880083    test_acc=0.704082
epoch= 58    train_loss = 1.481495    bag_loss = 0.361017    mse_loss = 0.737424 train_acc=0.840206    test_loss = 1.884008    test_acc=0.693878
epoch= 59    train_loss = 1.475178    bag_loss = 0.356095    mse_loss = 0.737061 train_acc=0.845361    test_loss = 1.887836    test_acc=0.693878
epoch= 60    train_loss = 1.469256    bag_loss = 0.351558    mse_loss = 0.736631 train_acc=0.845361    test_loss = 1.892723    test_acc=0.683673
epoch= 61    train_loss = 1.463149    bag_loss = 0.346800    mse_loss = 0.736200 train_acc=0.845361    test_loss = 1.896922    test_acc=0.683673
epoch= 62    train_loss = 1.456636    bag_loss = 0.341424    mse_loss = 0.735909 train_acc=0.850515    test_loss = 1.902003    test_acc=0.683673
epoch= 63    train_loss = 1.450412    bag_loss = 0.336372    mse_loss = 0.735495 train_acc=0.855670    test_loss = 1.907960    test_acc=0.683673
epoch= 64    train_loss = 1.443433    bag_loss = 0.330468    mse_loss = 0.735111 train_acc=0.855670    test_loss = 1.913902    test_acc=0.683673
epoch= 65    train_loss = 1.437359    bag_loss = 0.325490    mse_loss = 0.734603 train_acc=0.855670    test_loss = 1.920733    test_acc=0.673469
epoch= 66    train_loss = 1.430352    bag_loss = 0.319514    mse_loss = 0.734105 train_acc=0.855670    test_loss = 1.928352    test_acc=0.673469
epoch= 67    train_loss = 1.423715    bag_loss = 0.313775    mse_loss = 0.733669 train_acc=0.860825    test_loss = 1.936632    test_acc=0.653061
epoch= 68    train_loss = 1.415993    bag_loss = 0.306909    mse_loss = 0.733158 train_acc=0.860825    test_loss = 1.947554    test_acc=0.632653
epoch= 69    train_loss = 1.408662    bag_loss = 0.300438    mse_loss = 0.732558 train_acc=0.860825    test_loss = 1.959827    test_acc=0.632653
epoch= 70    train_loss = 1.400547    bag_loss = 0.293119    mse_loss = 0.731952 train_acc=0.871134    test_loss = 1.968221    test_acc=0.632653
epoch= 71    train_loss = 1.392720    bag_loss = 0.285994    mse_loss = 0.731383 train_acc=0.881443    test_loss = 1.980835    test_acc=0.622449
epoch= 72    train_loss = 1.384148    bag_loss = 0.278168    mse_loss = 0.730695 train_acc=0.881443    test_loss = 1.992051    test_acc=0.612245
epoch= 73    train_loss = 1.376212    bag_loss = 0.270959    mse_loss = 0.729986 train_acc=0.891753    test_loss = 2.007256    test_acc=0.612245
epoch= 74    train_loss = 1.367445    bag_loss = 0.262972    mse_loss = 0.729180 train_acc=0.891753    test_loss = 2.019509    test_acc=0.612245
epoch= 75    train_loss = 1.359653    bag_loss = 0.256047    mse_loss = 0.728229 train_acc=0.891753    test_loss = 2.032956    test_acc=0.612245
epoch= 76    train_loss = 1.350608    bag_loss = 0.247912    mse_loss = 0.727213 train_acc=0.907216    test_loss = 2.048687    test_acc=0.622449
epoch= 77    train_loss = 1.341903    bag_loss = 0.240108    mse_loss = 0.726171 train_acc=0.912371    test_loss = 2.064431    test_acc=0.622449
epoch= 78    train_loss = 1.334386    bag_loss = 0.233399    mse_loss = 0.725178 train_acc=0.917526    test_loss = 2.082227    test_acc=0.612245
epoch= 79    train_loss = 1.324932    bag_loss = 0.224635    mse_loss = 0.724241 train_acc=0.917526    test_loss = 2.100701    test_acc=0.612245
epoch= 80    train_loss = 1.316430    bag_loss = 0.216907    mse_loss = 0.723184 train_acc=0.927835    test_loss = 2.115489    test_acc=0.622449
epoch= 81    train_loss = 1.306594    bag_loss = 0.207784    mse_loss = 0.722146 train_acc=0.932990    test_loss = 2.138024    test_acc=0.622449
epoch= 82    train_loss = 1.298533    bag_loss = 0.200487    mse_loss = 0.721023 train_acc=0.938144    test_loss = 2.152648    test_acc=0.622449
epoch= 83    train_loss = 1.290544    bag_loss = 0.193333    mse_loss = 0.719805 train_acc=0.938144    test_loss = 2.173630    test_acc=0.622449
epoch= 84    train_loss = 1.282016    bag_loss = 0.185509    mse_loss = 0.718704 train_acc=0.938144    test_loss = 2.196087    test_acc=0.622449
epoch= 85    train_loss = 1.273775    bag_loss = 0.178106    mse_loss = 0.717462 train_acc=0.938144    test_loss = 2.212843    test_acc=0.622449
epoch= 86    train_loss = 1.265079    bag_loss = 0.170207    mse_loss = 0.716227 train_acc=0.943299    test_loss = 2.234642    test_acc=0.622449
epoch= 87    train_loss = 1.256709    bag_loss = 0.162722    mse_loss = 0.714906 train_acc=0.948454    test_loss = 2.262234    test_acc=0.622449
epoch= 88    train_loss = 1.248730    bag_loss = 0.155614    mse_loss = 0.713575 train_acc=0.953608    test_loss = 2.282762    test_acc=0.622449
epoch= 89    train_loss = 1.240210    bag_loss = 0.147998    mse_loss = 0.712200 train_acc=0.963918    test_loss = 2.304814    test_acc=0.612245
epoch= 90    train_loss = 1.232595    bag_loss = 0.141213    mse_loss = 0.710882 train_acc=0.969072    test_loss = 2.329849    test_acc=0.602041
epoch= 91    train_loss = 1.223531    bag_loss = 0.133105    mse_loss = 0.709430 train_acc=0.969072    test_loss = 2.350020    test_acc=0.602041
epoch= 92    train_loss = 1.216627    bag_loss = 0.127029    mse_loss = 0.708115 train_acc=0.969072    test_loss = 2.381543    test_acc=0.602041
epoch= 93    train_loss = 1.208160    bag_loss = 0.119489    mse_loss = 0.706696 train_acc=0.969072    test_loss = 2.404398    test_acc=0.612245
epoch= 94    train_loss = 1.200697    bag_loss = 0.112947    mse_loss = 0.705315 train_acc=0.969072    test_loss = 2.434469    test_acc=0.622449
epoch= 95    train_loss = 1.193620    bag_loss = 0.106817    mse_loss = 0.703925 train_acc=0.969072    test_loss = 2.463739    test_acc=0.622449
epoch= 96    train_loss = 1.185512    bag_loss = 0.099641    mse_loss = 0.702568 train_acc=0.974227    test_loss = 2.490636    test_acc=0.622449
epoch= 97    train_loss = 1.179380    bag_loss = 0.094401    mse_loss = 0.701265 train_acc=0.979381    test_loss = 2.517568    test_acc=0.622449
epoch= 98    train_loss = 1.173107    bag_loss = 0.088949    mse_loss = 0.700060 train_acc=0.979381    test_loss = 2.551626    test_acc=0.612245
epoch= 99    train_loss = 1.166450    bag_loss = 0.083125    mse_loss = 0.698887 train_acc=0.989691    test_loss = 2.590245    test_acc=0.622449
epoch= 100    train_loss = 1.159578    bag_loss = 0.077075    mse_loss = 0.697753 train_acc=0.994845    test_loss = 2.620133    test_acc=0.612245
epoch= 101    train_loss = 1.153742    bag_loss = 0.072162    mse_loss = 0.696583 train_acc=0.994845    test_loss = 2.654599    test_acc=0.622449
epoch= 102    train_loss = 1.147815    bag_loss = 0.067113    mse_loss = 0.695512 train_acc=0.994845    test_loss = 2.686724    test_acc=0.622449
epoch= 103    train_loss = 1.141711    bag_loss = 0.062000    mse_loss = 0.694406 train_acc=0.994845    test_loss = 2.717698    test_acc=0.612245
epoch= 104    train_loss = 1.136025    bag_loss = 0.057404    mse_loss = 0.693280 train_acc=0.994845    test_loss = 2.742269    test_acc=0.612245
epoch= 105    train_loss = 1.131682    bag_loss = 0.054192    mse_loss = 0.692224 train_acc=0.994845    test_loss = 2.769705    test_acc=0.612245
epoch= 106    train_loss = 1.127109    bag_loss = 0.050790    mse_loss = 0.691173 train_acc=0.994845    test_loss = 2.797890    test_acc=0.602041
epoch= 107    train_loss = 1.121782    bag_loss = 0.046707    mse_loss = 0.690169 train_acc=0.994845    test_loss = 2.826725    test_acc=0.602041
epoch= 108    train_loss = 1.117272    bag_loss = 0.043594    mse_loss = 0.689109 train_acc=0.994845    test_loss = 2.848359    test_acc=0.602041
epoch= 109    train_loss = 1.113758    bag_loss = 0.041507    mse_loss = 0.688127 train_acc=0.994845    test_loss = 2.875313    test_acc=0.602041
epoch= 110    train_loss = 1.109792    bag_loss = 0.039017    mse_loss = 0.687175 train_acc=1.000000    test_loss = 2.901471    test_acc=0.602041
epoch= 111    train_loss = 1.105014    bag_loss = 0.035828    mse_loss = 0.686216 train_acc=1.000000    test_loss = 2.920429    test_acc=0.602041
epoch= 112    train_loss = 1.102153    bag_loss = 0.034618    mse_loss = 0.685271 train_acc=1.000000    test_loss = 2.925818    test_acc=0.591837
epoch= 113    train_loss = 1.098417    bag_loss = 0.032633    mse_loss = 0.684340 train_acc=1.000000    test_loss = 2.952183    test_acc=0.602041
epoch= 114    train_loss = 1.095241    bag_loss = 0.031207    mse_loss = 0.683470 train_acc=1.000000    test_loss = 2.971915    test_acc=0.591837
epoch= 115    train_loss = 1.090958    bag_loss = 0.028794    mse_loss = 0.682586 train_acc=1.000000    test_loss = 2.987739    test_acc=0.591837
epoch= 116    train_loss = 1.088011    bag_loss = 0.027838    mse_loss = 0.681688 train_acc=1.000000    test_loss = 2.992767    test_acc=0.591837
epoch= 117    train_loss = 1.084583    bag_loss = 0.026434    mse_loss = 0.680843 train_acc=1.000000    test_loss = 3.002806    test_acc=0.591837
epoch= 118    train_loss = 1.082435    bag_loss = 0.026340    mse_loss = 0.680009 train_acc=1.000000    test_loss = 3.005493    test_acc=0.591837
epoch= 119    train_loss = 1.079917    bag_loss = 0.025730    mse_loss = 0.679261 train_acc=1.000000    test_loss = 3.045652    test_acc=0.581633
epoch= 120    train_loss = 1.075120    bag_loss = 0.023019    mse_loss = 0.678430 train_acc=1.000000    test_loss = 3.079729    test_acc=0.581633
epoch= 121    train_loss = 1.071638    bag_loss = 0.021751    mse_loss = 0.677627 train_acc=1.000000    test_loss = 3.088378    test_acc=0.581633
epoch= 122    train_loss = 1.068700    bag_loss = 0.021050    mse_loss = 0.676852 train_acc=1.000000    test_loss = 3.083702    test_acc=0.581633
epoch= 123    train_loss = 1.065397    bag_loss = 0.020072    mse_loss = 0.676084 train_acc=1.000000    test_loss = 3.065422    test_acc=0.581633
epoch= 124    train_loss = 1.063165    bag_loss = 0.020105    mse_loss = 0.675400 train_acc=1.000000    test_loss = 3.077226    test_acc=0.581633
epoch= 125    train_loss = 1.059849    bag_loss = 0.019113    mse_loss = 0.674700 train_acc=1.000000    test_loss = 3.089494    test_acc=0.581633
epoch= 126    train_loss = 1.056482    bag_loss = 0.018112    mse_loss = 0.673995 train_acc=1.000000    test_loss = 3.108882    test_acc=0.571429
epoch= 127    train_loss = 1.053502    bag_loss = 0.017613    mse_loss = 0.673313 train_acc=1.000000    test_loss = 3.096689    test_acc=0.581633
epoch= 128    train_loss = 1.050729    bag_loss = 0.017275    mse_loss = 0.672713 train_acc=1.000000    test_loss = 3.081407    test_acc=0.581633
epoch= 129    train_loss = 1.047963    bag_loss = 0.016972    mse_loss = 0.672100 train_acc=1.000000    test_loss = 3.084544    test_acc=0.571429
epoch= 130    train_loss = 1.045831    bag_loss = 0.017282    mse_loss = 0.671489 train_acc=1.000000    test_loss = 3.070249    test_acc=0.581633
epoch= 131    train_loss = 1.044524    bag_loss = 0.018254    mse_loss = 0.670926 train_acc=1.000000    test_loss = 3.084308    test_acc=0.581633
epoch= 132    train_loss = 1.040802    bag_loss = 0.016678    mse_loss = 0.670388 train_acc=1.000000    test_loss = 3.107227    test_acc=0.581633
epoch= 133    train_loss = 1.037038    bag_loss = 0.015328    mse_loss = 0.669806 train_acc=1.000000    test_loss = 3.116500    test_acc=0.591837
epoch= 134    train_loss = 1.034418    bag_loss = 0.015136    mse_loss = 0.669299 train_acc=1.000000    test_loss = 3.096453    test_acc=0.591837
epoch= 135    train_loss = 1.031999    bag_loss = 0.015203    mse_loss = 0.668729 train_acc=1.000000    test_loss = 3.051535    test_acc=0.581633
epoch= 136    train_loss = 1.161101    bag_loss = 0.146101    mse_loss = 0.668854 train_acc=0.963918    test_loss = 3.037395    test_acc=0.602041
epoch= 137    train_loss = 1.071408    bag_loss = 0.057439    mse_loss = 0.668969 train_acc=0.979381    test_loss = 3.026499    test_acc=0.581633
epoch= 138    train_loss = 1.048319    bag_loss = 0.034966    mse_loss = 0.668304 train_acc=0.994845    test_loss = 3.025883    test_acc=0.622449
epoch= 139    train_loss = 1.042983    bag_loss = 0.030326    mse_loss = 0.667799 train_acc=0.994845    test_loss = 3.001555    test_acc=0.581633
epoch= 140    train_loss = 1.032962    bag_loss = 0.020991    mse_loss = 0.667384 train_acc=1.000000    test_loss = 3.010631    test_acc=0.591837
epoch= 141    train_loss = 1.030602    bag_loss = 0.019371    mse_loss = 0.667012 train_acc=1.000000    test_loss = 3.019299    test_acc=0.591837
epoch= 142    train_loss = 1.027933    bag_loss = 0.017488    mse_loss = 0.666668 train_acc=1.000000    test_loss = 3.027961    test_acc=0.602041
epoch= 143    train_loss = 1.026124    bag_loss = 0.016521    mse_loss = 0.666324 train_acc=1.000000    test_loss = 3.042817    test_acc=0.602041
epoch= 144    train_loss = 1.024386    bag_loss = 0.015661    mse_loss = 0.666010 train_acc=1.000000    test_loss = 3.046393    test_acc=0.602041
epoch= 145    train_loss = 1.022793    bag_loss = 0.015006    mse_loss = 0.665695 train_acc=1.000000    test_loss = 3.052867    test_acc=0.591837
epoch= 146    train_loss = 1.021319    bag_loss = 0.014520    mse_loss = 0.665404 train_acc=1.000000    test_loss = 3.059037    test_acc=0.581633
epoch= 147    train_loss = 1.019670    bag_loss = 0.013931    mse_loss = 0.665099 train_acc=1.000000    test_loss = 3.061568    test_acc=0.591837
epoch= 148    train_loss = 1.018247    bag_loss = 0.013628    mse_loss = 0.664805 train_acc=1.000000    test_loss = 3.065960    test_acc=0.581633
epoch= 149    train_loss = 1.016576    bag_loss = 0.013174    mse_loss = 0.664504 train_acc=1.000000    test_loss = 3.064267    test_acc=0.581633
epoch= 150    train_loss = 1.015065    bag_loss = 0.012949    mse_loss = 0.664206 train_acc=1.000000    test_loss = 3.067114    test_acc=0.581633
epoch= 151    train_loss = 1.013554    bag_loss = 0.012783    mse_loss = 0.663918 train_acc=1.000000    test_loss = 3.060873    test_acc=0.581633
epoch= 152    train_loss = 1.011984    bag_loss = 0.012612    mse_loss = 0.663642 train_acc=1.000000    test_loss = 3.057508    test_acc=0.571429
epoch= 153    train_loss = 1.010469    bag_loss = 0.012568    mse_loss = 0.663362 train_acc=1.000000    test_loss = 3.051305    test_acc=0.581633
epoch= 154    train_loss = 1.009059    bag_loss = 0.012656    mse_loss = 0.663112 train_acc=1.000000    test_loss = 3.050690    test_acc=0.581633
epoch= 155    train_loss = 1.007565    bag_loss = 0.012695    mse_loss = 0.662858 train_acc=1.000000    test_loss = 3.041249    test_acc=0.581633
epoch= 156    train_loss = 1.005685    bag_loss = 0.012413    mse_loss = 0.662596 train_acc=1.000000    test_loss = 3.043484    test_acc=0.581633
epoch= 157    train_loss = 1.004208    bag_loss = 0.012576    mse_loss = 0.662368 train_acc=1.000000    test_loss = 3.033021    test_acc=0.571429
epoch= 158    train_loss = 1.002696    bag_loss = 0.012686    mse_loss = 0.662148 train_acc=1.000000    test_loss = 3.038455    test_acc=0.571429
epoch= 159    train_loss = 1.000970    bag_loss = 0.012666    mse_loss = 0.661901 train_acc=1.000000    test_loss = 3.028626    test_acc=0.571429
epoch= 160    train_loss = 0.999583    bag_loss = 0.012917    mse_loss = 0.661705 train_acc=1.000000    test_loss = 3.020618    test_acc=0.581633
epoch= 161    train_loss = 1.111041    bag_loss = 0.125790    mse_loss = 0.661746 train_acc=0.969072    test_loss = 2.812660    test_acc=0.642857
epoch= 162    train_loss = 1.078233    bag_loss = 0.094548    mse_loss = 0.661920 train_acc=0.979381    test_loss = 2.935191    test_acc=0.581633
epoch= 163    train_loss = 1.002167    bag_loss = 0.019214    mse_loss = 0.661438 train_acc=1.000000    test_loss = 2.919017    test_acc=0.591837
epoch= 164    train_loss = 0.999550    bag_loss = 0.017090    mse_loss = 0.661183 train_acc=1.000000    test_loss = 2.921871    test_acc=0.591837
epoch= 165    train_loss = 0.997635    bag_loss = 0.015701    mse_loss = 0.660980 train_acc=1.000000    test_loss = 2.929208    test_acc=0.581633
epoch= 166    train_loss = 0.996128    bag_loss = 0.014748    mse_loss = 0.660801 train_acc=1.000000    test_loss = 2.933042    test_acc=0.571429
epoch= 167    train_loss = 0.994857    bag_loss = 0.014084    mse_loss = 0.660635 train_acc=1.000000    test_loss = 2.938891    test_acc=0.571429
epoch= 168    train_loss = 0.993654    bag_loss = 0.013548    mse_loss = 0.660464 train_acc=1.000000    test_loss = 2.944453    test_acc=0.571429
epoch= 169    train_loss = 0.992504    bag_loss = 0.013128    mse_loss = 0.660296 train_acc=1.000000    test_loss = 2.951385    test_acc=0.571429
epoch= 170    train_loss = 0.991429    bag_loss = 0.012828    mse_loss = 0.660134 train_acc=1.000000    test_loss = 2.957139    test_acc=0.571429
epoch= 171    train_loss = 0.990345    bag_loss = 0.012577    mse_loss = 0.659978 train_acc=1.000000    test_loss = 2.963601    test_acc=0.571429
epoch= 172    train_loss = 0.989268    bag_loss = 0.012389    mse_loss = 0.659818 train_acc=1.000000    test_loss = 2.969662    test_acc=0.571429
epoch= 173    train_loss = 0.988144    bag_loss = 0.012195    mse_loss = 0.659678 train_acc=1.000000    test_loss = 2.972715    test_acc=0.571429
epoch= 174    train_loss = 0.987022    bag_loss = 0.012073    mse_loss = 0.659525 train_acc=1.000000    test_loss = 2.975976    test_acc=0.571429
epoch= 175    train_loss = 0.985812    bag_loss = 0.011925    mse_loss = 0.659376 train_acc=1.000000    test_loss = 2.980594    test_acc=0.571429
epoch= 176    train_loss = 0.984671    bag_loss = 0.011915    mse_loss = 0.659221 train_acc=1.000000    test_loss = 2.980754    test_acc=0.571429
epoch= 177    train_loss = 0.983481    bag_loss = 0.011891    mse_loss = 0.659084 train_acc=1.000000    test_loss = 2.982666    test_acc=0.571429
epoch= 178    train_loss = 0.982333    bag_loss = 0.011970    mse_loss = 0.658930 train_acc=1.000000    test_loss = 2.982111    test_acc=0.571429
epoch= 179    train_loss = 0.981113    bag_loss = 0.011999    mse_loss = 0.658780 train_acc=1.000000    test_loss = 2.978878    test_acc=0.581633
epoch= 180    train_loss = 0.980065    bag_loss = 0.012240    mse_loss = 0.658632 train_acc=1.000000    test_loss = 2.978833    test_acc=0.591837
epoch= 181    train_loss = 0.978885    bag_loss = 0.012333    mse_loss = 0.658502 train_acc=1.000000    test_loss = 2.968349    test_acc=0.591837
epoch= 182    train_loss = 1.081110    bag_loss = 0.115533    mse_loss = 0.658628 train_acc=0.974227    test_loss = 2.767077    test_acc=0.632653
epoch= 183    train_loss = 0.995015    bag_loss = 0.030226    mse_loss = 0.658780 train_acc=1.000000    test_loss = 2.896697    test_acc=0.591837
epoch= 184    train_loss = 0.979307    bag_loss = 0.015067    mse_loss = 0.658355 train_acc=1.000000    test_loss = 2.893559    test_acc=0.591837
epoch= 185    train_loss = 0.977525    bag_loss = 0.013891    mse_loss = 0.658139 train_acc=1.000000    test_loss = 2.902886    test_acc=0.591837
epoch= 186    train_loss = 0.976127    bag_loss = 0.013127    mse_loss = 0.657984 train_acc=1.000000    test_loss = 2.912604    test_acc=0.591837
epoch= 187    train_loss = 0.974904    bag_loss = 0.012585    mse_loss = 0.657846 train_acc=1.000000    test_loss = 2.917964    test_acc=0.591837
epoch= 188    train_loss = 0.973854    bag_loss = 0.012271    mse_loss = 0.657718 train_acc=1.000000    test_loss = 2.928183    test_acc=0.591837
epoch= 189    train_loss = 0.972884    bag_loss = 0.012065    mse_loss = 0.657604 train_acc=1.000000    test_loss = 2.934152    test_acc=0.591837
epoch= 190    train_loss = 0.971863    bag_loss = 0.011850    mse_loss = 0.657492 train_acc=1.000000    test_loss = 2.940340    test_acc=0.591837
epoch= 191    train_loss = 0.970815    bag_loss = 0.011658    mse_loss = 0.657380 train_acc=1.000000    test_loss = 2.944456    test_acc=0.581633
epoch= 192    train_loss = 0.969820    bag_loss = 0.011582    mse_loss = 0.657268 train_acc=1.000000    test_loss = 2.949933    test_acc=0.581633
epoch= 193    train_loss = 0.968774    bag_loss = 0.011489    mse_loss = 0.657151 train_acc=1.000000    test_loss = 2.950698    test_acc=0.581633
epoch= 194    train_loss = 0.967709    bag_loss = 0.011438    mse_loss = 0.657034 train_acc=1.000000    test_loss = 2.951969    test_acc=0.581633
epoch= 195    train_loss = 0.966650    bag_loss = 0.011438    mse_loss = 0.656920 train_acc=1.000000    test_loss = 2.953004    test_acc=0.581633
epoch= 196    train_loss = 0.965607    bag_loss = 0.011478    mse_loss = 0.656813 train_acc=1.000000    test_loss = 2.952595    test_acc=0.581633
epoch= 197    train_loss = 0.964403    bag_loss = 0.011391    mse_loss = 0.656702 train_acc=1.000000    test_loss = 2.954779    test_acc=0.581633
epoch= 198    train_loss = 0.963373    bag_loss = 0.011499    mse_loss = 0.656596 train_acc=1.000000    test_loss = 2.948478    test_acc=0.591837
[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]
[0.9998473525047302, 0.0631580650806427, 1.1190461009391584e-05, 0.999422013759613, 0.9875795245170593, 0.9995861053466797, 0.01982554793357849, 0.9962817430496216, 0.9994829893112183, 0.9840087890625, 0.9116839170455933, 0.9985097050666809, 0.9990698099136353, 0.5213971138000488, 0.9813603162765503, 0.9944487810134888, 0.7781095504760742, 0.9982569813728333, 0.0013993382453918457, 0.24066707491874695, 0.5937686562538147, 2.2226191504159942e-05, 0.06826624274253845, 0.9999366998672485, 0.9999487400054932, 0.007727891206741333, 0.0025890767574310303, 0.990547776222229, 0.9989942312240601, 0.9999409914016724, 0.9650585055351257, 0.031376808881759644, 0.09562137722969055, 0.028408586978912354, 0.0004297196865081787, 0.9795123338699341, 0.9995198249816895, 0.4172157645225525, 0.9585500955581665, 0.006886422634124756, 0.9931527376174927, 0.9921424984931946, 0.27390560507774353, 0.0028047263622283936, 0.9997977018356323, 0.9574714303016663, 0.017998963594436646, 0.9955734610557556, 0.7479216456413269, 0.0013433396816253662, 0.6481711268424988, 0.0008518993854522705, 0.012721538543701172, 0.013517439365386963, 0.014079391956329346, 0.9742454290390015, 4.028746843687259e-06, 0.9999862313270569, 0.9980942606925964, 0.0006200969219207764, 0.9977730512619019, 0.0004433095455169678, 0.003906726837158203, 0.20904338359832764, 0.9986512660980225, 0.9995353817939758, 0.5946022272109985, 0.0009136497974395752, 0.08353778719902039, 0.11314213275909424, 0.9169500470161438, 0.9973145127296448, 0.835669994354248, 0.9997525215148926, 0.9995652437210083, 0.8910290598869324, 0.9970961213111877, 0.16616442799568176, 0.0004337728023529053, 1.2887612683698535e-05, 0.00015798211097717285, 0.999731183052063, 0.000667870044708252, 0.9855495095252991, 0.95979905128479, 0.9999739527702332, 0.06053474545478821, 0.999887228012085, 0.23666337132453918, 8.09786724857986e-05, 0.07790994644165039, 0.04098612070083618, 0.20255106687545776, 0.0004380643367767334, 0.1620258390903473, 0.1587706208229065, 0.9850960969924927, 0.9796186685562134]
epoch= 199    train_loss = 0.962260    bag_loss = 0.011543    mse_loss = 0.656489 train_acc=1.000000    test_loss = 2.943703    test_acc=0.591837
Ground truth: [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], Predicted: [0.9998473525047302, 0.0631580650806427, 1.1190461009391584e-05, 0.999422013759613, 0.9875795245170593, 0.9995861053466797, 0.01982554793357849, 0.9962817430496216, 0.9994829893112183, 0.9840087890625, 0.9116839170455933, 0.9985097050666809, 0.9990698099136353, 0.5213971138000488, 0.9813603162765503, 0.9944487810134888, 0.7781095504760742, 0.9982569813728333, 0.0013993382453918457, 0.24066707491874695, 0.5937686562538147, 2.2226191504159942e-05, 0.06826624274253845, 0.9999366998672485, 0.9999487400054932, 0.007727891206741333, 0.0025890767574310303, 0.990547776222229, 0.9989942312240601, 0.9999409914016724, 0.9650585055351257, 0.031376808881759644, 0.09562137722969055, 0.028408586978912354, 0.0004297196865081787, 0.9795123338699341, 0.9995198249816895, 0.4172157645225525, 0.9585500955581665, 0.006886422634124756, 0.9931527376174927, 0.9921424984931946, 0.27390560507774353, 0.0028047263622283936, 0.9997977018356323, 0.9574714303016663, 0.017998963594436646, 0.9955734610557556, 0.7479216456413269, 0.0013433396816253662, 0.6481711268424988, 0.0008518993854522705, 0.012721538543701172, 0.013517439365386963, 0.014079391956329346, 0.9742454290390015, 4.028746843687259e-06, 0.9999862313270569, 0.9980942606925964, 0.0006200969219207764, 0.9977730512619019, 0.0004433095455169678, 0.003906726837158203, 0.20904338359832764, 0.9986512660980225, 0.9995353817939758, 0.5946022272109985, 0.0009136497974395752, 0.08353778719902039, 0.11314213275909424, 0.9169500470161438, 0.9973145127296448, 0.835669994354248, 0.9997525215148926, 0.9995652437210083, 0.8910290598869324, 0.9970961213111877, 0.16616442799568176, 0.0004337728023529053, 1.2887612683698535e-05, 0.00015798211097717285, 0.999731183052063, 0.000667870044708252, 0.9855495095252991, 0.95979905128479, 0.9999739527702332, 0.06053474545478821, 0.999887228012085, 0.23666337132453918, 8.09786724857986e-05, 0.07790994644165039, 0.04098612070083618, 0.20255106687545776, 0.0004380643367767334, 0.1620258390903473, 0.1587706208229065, 0.9850960969924927, 0.9796186685562134]
Runs: 0, Training fold:0
AUC =  0.6621315192743763
epoch= 0    train_loss = 3.424266    bag_loss = 0.700288    mse_loss = 1.290764 train_acc=0.364103    test_loss = 3.174683    test_acc=0.443299
epoch= 1    train_loss = 3.208910    bag_loss = 0.688281    mse_loss = 1.272192 train_acc=0.625641    test_loss = 2.960709    test_acc=0.659794
epoch= 2    train_loss = 2.957179    bag_loss = 0.679269    mse_loss = 1.181582 train_acc=0.682051    test_loss = 2.658376    test_acc=0.628866
epoch= 3    train_loss = 2.701074    bag_loss = 0.669677    mse_loss = 1.051643 train_acc=0.692308    test_loss = 2.468373    test_acc=0.659794
epoch= 4    train_loss = 2.553680    bag_loss = 0.656077    mse_loss = 1.018005 train_acc=0.707692    test_loss = 2.346034    test_acc=0.690722
epoch= 5    train_loss = 2.439212    bag_loss = 0.639954    mse_loss = 1.006411 train_acc=0.702564    test_loss = 2.244389    test_acc=0.711340
epoch= 6    train_loss = 2.341580    bag_loss = 0.622302    mse_loss = 1.000474 train_acc=0.717949    test_loss = 2.156194    test_acc=0.701031
epoch= 7    train_loss = 2.255546    bag_loss = 0.602974    mse_loss = 0.996464 train_acc=0.717949    test_loss = 2.077660    test_acc=0.711340
epoch= 8    train_loss = 2.180006    bag_loss = 0.583498    mse_loss = 0.992974 train_acc=0.728205    test_loss = 2.011899    test_acc=0.711340
epoch= 9    train_loss = 2.115917    bag_loss = 0.567020    mse_loss = 0.989225 train_acc=0.733333    test_loss = 1.957104    test_acc=0.721649
epoch= 10    train_loss = 2.062000    bag_loss = 0.553929    mse_loss = 0.984903 train_acc=0.733333    test_loss = 1.911705    test_acc=0.731959
epoch= 11    train_loss = 2.016120    bag_loss = 0.543441    mse_loss = 0.980014 train_acc=0.738462    test_loss = 1.874186    test_acc=0.742268
epoch= 12    train_loss = 1.976839    bag_loss = 0.535290    mse_loss = 0.974438 train_acc=0.743590    test_loss = 1.841838    test_acc=0.742268
epoch= 13    train_loss = 1.942324    bag_loss = 0.528429    mse_loss = 0.968197 train_acc=0.748718    test_loss = 1.813968    test_acc=0.742268
epoch= 14    train_loss = 1.911387    bag_loss = 0.522450    mse_loss = 0.961150 train_acc=0.748718    test_loss = 1.790109    test_acc=0.731959
epoch= 15    train_loss = 1.882707    bag_loss = 0.517014    mse_loss = 0.952867 train_acc=0.748718    test_loss = 1.769153    test_acc=0.742268
epoch= 16    train_loss = 1.855627    bag_loss = 0.512115    mse_loss = 0.943057 train_acc=0.748718    test_loss = 1.748400    test_acc=0.742268
epoch= 17    train_loss = 1.829677    bag_loss = 0.507816    mse_loss = 0.931562 train_acc=0.748718    test_loss = 1.729640    test_acc=0.752577
epoch= 18    train_loss = 1.805223    bag_loss = 0.504212    mse_loss = 0.919160 train_acc=0.753846    test_loss = 1.712267    test_acc=0.752577
epoch= 19    train_loss = 1.782453    bag_loss = 0.501205    mse_loss = 0.906502 train_acc=0.758974    test_loss = 1.696672    test_acc=0.752577
epoch= 20    train_loss = 1.762126    bag_loss = 0.498417    mse_loss = 0.895050 train_acc=0.764103    test_loss = 1.684098    test_acc=0.742268
epoch= 21    train_loss = 1.743916    bag_loss = 0.495304    mse_loss = 0.885326 train_acc=0.769231    test_loss = 1.673434    test_acc=0.742268
epoch= 22    train_loss = 1.728662    bag_loss = 0.492461    mse_loss = 0.877784 train_acc=0.769231    test_loss = 1.664565    test_acc=0.742268
epoch= 23    train_loss = 1.715613    bag_loss = 0.489854    mse_loss = 0.871900 train_acc=0.769231    test_loss = 1.657354    test_acc=0.742268
epoch= 24    train_loss = 1.704136    bag_loss = 0.487261    mse_loss = 0.867294 train_acc=0.769231    test_loss = 1.651439    test_acc=0.731959
epoch= 25    train_loss = 1.693834    bag_loss = 0.484468    mse_loss = 0.863821 train_acc=0.774359    test_loss = 1.646888    test_acc=0.731959
epoch= 26    train_loss = 1.684418    bag_loss = 0.481785    mse_loss = 0.860888 train_acc=0.779487    test_loss = 1.643224    test_acc=0.731959
epoch= 27    train_loss = 1.676083    bag_loss = 0.479285    mse_loss = 0.858677 train_acc=0.784615    test_loss = 1.639880    test_acc=0.731959
epoch= 28    train_loss = 1.668271    bag_loss = 0.476743    mse_loss = 0.856877 train_acc=0.784615    test_loss = 1.637456    test_acc=0.731959
epoch= 29    train_loss = 1.660875    bag_loss = 0.474130    mse_loss = 0.855418 train_acc=0.794872    test_loss = 1.635072    test_acc=0.731959
epoch= 30    train_loss = 1.653780    bag_loss = 0.471461    mse_loss = 0.854169 train_acc=0.794872    test_loss = 1.632896    test_acc=0.721649
epoch= 31    train_loss = 1.647286    bag_loss = 0.469139    mse_loss = 0.853070 train_acc=0.794872    test_loss = 1.630860    test_acc=0.721649
epoch= 32    train_loss = 1.640031    bag_loss = 0.466689    mse_loss = 0.851224 train_acc=0.794872    test_loss = 1.627645    test_acc=0.721649
epoch= 33    train_loss = 1.633061    bag_loss = 0.464335    mse_loss = 0.849380 train_acc=0.794872    test_loss = 1.626000    test_acc=0.721649
epoch= 34    train_loss = 1.627268    bag_loss = 0.461990    mse_loss = 0.848587 train_acc=0.800000    test_loss = 1.624194    test_acc=0.721649
epoch= 35    train_loss = 1.621696    bag_loss = 0.459658    mse_loss = 0.847921 train_acc=0.800000    test_loss = 1.622903    test_acc=0.721649
epoch= 36    train_loss = 1.616394    bag_loss = 0.457456    mse_loss = 0.847313 train_acc=0.805128    test_loss = 1.621662    test_acc=0.721649
epoch= 37    train_loss = 1.611579    bag_loss = 0.455549    mse_loss = 0.846821 train_acc=0.805128    test_loss = 1.620445    test_acc=0.711340
epoch= 38    train_loss = 1.606605    bag_loss = 0.453340    mse_loss = 0.846388 train_acc=0.805128    test_loss = 1.619437    test_acc=0.711340
epoch= 39    train_loss = 1.601835    bag_loss = 0.451236    mse_loss = 0.845977 train_acc=0.805128    test_loss = 1.618278    test_acc=0.711340
epoch= 40    train_loss = 1.597189    bag_loss = 0.449170    mse_loss = 0.845561 train_acc=0.805128    test_loss = 1.617459    test_acc=0.711340
epoch= 41    train_loss = 1.592703    bag_loss = 0.447149    mse_loss = 0.845185 train_acc=0.805128    test_loss = 1.617157    test_acc=0.711340
epoch= 42    train_loss = 1.588271    bag_loss = 0.445110    mse_loss = 0.844825 train_acc=0.810256    test_loss = 1.616854    test_acc=0.711340
epoch= 43    train_loss = 1.583877    bag_loss = 0.442956    mse_loss = 0.844528 train_acc=0.810256    test_loss = 1.616541    test_acc=0.711340
epoch= 44    train_loss = 1.579555    bag_loss = 0.440826    mse_loss = 0.844209 train_acc=0.815385    test_loss = 1.616317    test_acc=0.711340
epoch= 45    train_loss = 1.575104    bag_loss = 0.438500    mse_loss = 0.843899 train_acc=0.815385    test_loss = 1.615722    test_acc=0.731959
epoch= 46    train_loss = 1.570536    bag_loss = 0.435994    mse_loss = 0.843561 train_acc=0.815385    test_loss = 1.616134    test_acc=0.731959
epoch= 47    train_loss = 1.566277    bag_loss = 0.433735    mse_loss = 0.843237 train_acc=0.815385    test_loss = 1.615468    test_acc=0.731959
epoch= 48    train_loss = 1.561617    bag_loss = 0.430996    mse_loss = 0.842918 train_acc=0.815385    test_loss = 1.616264    test_acc=0.711340
epoch= 49    train_loss = 1.557248    bag_loss = 0.428498    mse_loss = 0.842550 train_acc=0.815385    test_loss = 1.616912    test_acc=0.711340
epoch= 50    train_loss = 1.552853    bag_loss = 0.425881    mse_loss = 0.842229 train_acc=0.815385    test_loss = 1.617289    test_acc=0.690722
epoch= 51    train_loss = 1.548628    bag_loss = 0.423347    mse_loss = 0.841950 train_acc=0.815385    test_loss = 1.617792    test_acc=0.690722
epoch= 52    train_loss = 1.544334    bag_loss = 0.420644    mse_loss = 0.841712 train_acc=0.815385    test_loss = 1.618642    test_acc=0.690722
epoch= 53    train_loss = 1.540181    bag_loss = 0.418008    mse_loss = 0.841484 train_acc=0.815385    test_loss = 1.619128    test_acc=0.680412
epoch= 54    train_loss = 1.536095    bag_loss = 0.415391    mse_loss = 0.841262 train_acc=0.815385    test_loss = 1.620660    test_acc=0.680412
epoch= 55    train_loss = 1.532007    bag_loss = 0.412697    mse_loss = 0.841065 train_acc=0.810256    test_loss = 1.621517    test_acc=0.680412
epoch= 56    train_loss = 1.527948    bag_loss = 0.409989    mse_loss = 0.840873 train_acc=0.810256    test_loss = 1.622940    test_acc=0.680412
epoch= 57    train_loss = 1.523794    bag_loss = 0.407105    mse_loss = 0.840710 train_acc=0.820513    test_loss = 1.624206    test_acc=0.680412
epoch= 58    train_loss = 1.519889    bag_loss = 0.404463    mse_loss = 0.840516 train_acc=0.820513    test_loss = 1.626200    test_acc=0.680412
epoch= 59    train_loss = 1.516157    bag_loss = 0.401931    mse_loss = 0.840344 train_acc=0.825641    test_loss = 1.627831    test_acc=0.680412
epoch= 60    train_loss = 1.512250    bag_loss = 0.399155    mse_loss = 0.840192 train_acc=0.830769    test_loss = 1.629760    test_acc=0.680412
epoch= 61    train_loss = 1.508416    bag_loss = 0.396422    mse_loss = 0.840034 train_acc=0.835897    test_loss = 1.631738    test_acc=0.680412
epoch= 62    train_loss = 1.504481    bag_loss = 0.393546    mse_loss = 0.839877 train_acc=0.830769    test_loss = 1.633893    test_acc=0.670103
epoch= 63    train_loss = 1.500739    bag_loss = 0.390826    mse_loss = 0.839720 train_acc=0.830769    test_loss = 1.636004    test_acc=0.670103
epoch= 64    train_loss = 1.496963    bag_loss = 0.388026    mse_loss = 0.839554 train_acc=0.830769    test_loss = 1.638788    test_acc=0.659794
epoch= 65    train_loss = 1.493304    bag_loss = 0.385298    mse_loss = 0.839409 train_acc=0.830769    test_loss = 1.641203    test_acc=0.659794
epoch= 66    train_loss = 1.489907    bag_loss = 0.382818    mse_loss = 0.839256 train_acc=0.841026    test_loss = 1.643805    test_acc=0.659794
epoch= 67    train_loss = 1.486466    bag_loss = 0.380262    mse_loss = 0.839104 train_acc=0.841026    test_loss = 1.646987    test_acc=0.659794
epoch= 68    train_loss = 1.483214    bag_loss = 0.377874    mse_loss = 0.838960 train_acc=0.841026    test_loss = 1.649308    test_acc=0.659794
epoch= 69    train_loss = 1.479973    bag_loss = 0.375506    mse_loss = 0.838785 train_acc=0.846154    test_loss = 1.652117    test_acc=0.659794
epoch= 70    train_loss = 1.476793    bag_loss = 0.373178    mse_loss = 0.838622 train_acc=0.846154    test_loss = 1.655688    test_acc=0.659794
epoch= 71    train_loss = 1.473550    bag_loss = 0.370769    mse_loss = 0.838456 train_acc=0.846154    test_loss = 1.658016    test_acc=0.659794
epoch= 72    train_loss = 1.470743    bag_loss = 0.368802    mse_loss = 0.838267 train_acc=0.856410    test_loss = 1.660898    test_acc=0.659794
epoch= 73    train_loss = 1.467690    bag_loss = 0.366546    mse_loss = 0.838112 train_acc=0.856410    test_loss = 1.663585    test_acc=0.659794
epoch= 74    train_loss = 1.464720    bag_loss = 0.364369    mse_loss = 0.837940 train_acc=0.856410    test_loss = 1.666458    test_acc=0.659794
epoch= 75    train_loss = 1.462051    bag_loss = 0.362442    mse_loss = 0.837805 train_acc=0.861538    test_loss = 1.669003    test_acc=0.659794
epoch= 76    train_loss = 1.459022    bag_loss = 0.360145    mse_loss = 0.837669 train_acc=0.866667    test_loss = 1.672177    test_acc=0.659794
epoch= 77    train_loss = 1.456446    bag_loss = 0.358286    mse_loss = 0.837525 train_acc=0.866667    test_loss = 1.673873    test_acc=0.659794
epoch= 78    train_loss = 1.453767    bag_loss = 0.356307    mse_loss = 0.837377 train_acc=0.861538    test_loss = 1.676986    test_acc=0.670103
epoch= 79    train_loss = 1.450984    bag_loss = 0.354222    mse_loss = 0.837215 train_acc=0.861538    test_loss = 1.679956    test_acc=0.659794
epoch= 80    train_loss = 1.448321    bag_loss = 0.352239    mse_loss = 0.837045 train_acc=0.861538    test_loss = 1.682470    test_acc=0.670103
epoch= 81    train_loss = 1.445704    bag_loss = 0.350292    mse_loss = 0.836875 train_acc=0.861538    test_loss = 1.685840    test_acc=0.659794
epoch= 82    train_loss = 1.442867    bag_loss = 0.348110    mse_loss = 0.836704 train_acc=0.866667    test_loss = 1.688525    test_acc=0.670103
epoch= 83    train_loss = 1.440358    bag_loss = 0.346255    mse_loss = 0.836510 train_acc=0.866667    test_loss = 1.691609    test_acc=0.659794
epoch= 84    train_loss = 1.437828    bag_loss = 0.344336    mse_loss = 0.836338 train_acc=0.866667    test_loss = 1.694788    test_acc=0.659794
epoch= 85    train_loss = 1.435236    bag_loss = 0.342354    mse_loss = 0.836138 train_acc=0.861538    test_loss = 1.697868    test_acc=0.659794
epoch= 86    train_loss = 1.432576    bag_loss = 0.340281    mse_loss = 0.835943 train_acc=0.866667    test_loss = 1.700717    test_acc=0.649485
epoch= 87    train_loss = 1.429875    bag_loss = 0.338170    mse_loss = 0.835738 train_acc=0.871795    test_loss = 1.703351    test_acc=0.649485
epoch= 88    train_loss = 1.427238    bag_loss = 0.336099    mse_loss = 0.835531 train_acc=0.871795    test_loss = 1.706716    test_acc=0.649485
epoch= 89    train_loss = 1.424226    bag_loss = 0.333652    mse_loss = 0.835297 train_acc=0.866667    test_loss = 1.708929    test_acc=0.649485
epoch= 90    train_loss = 1.421561    bag_loss = 0.331509    mse_loss = 0.835069 train_acc=0.871795    test_loss = 1.712496    test_acc=0.649485
epoch= 91    train_loss = 1.418591    bag_loss = 0.329080    mse_loss = 0.834799 train_acc=0.871795    test_loss = 1.716615    test_acc=0.649485
epoch= 92    train_loss = 1.416066    bag_loss = 0.327066    mse_loss = 0.834539 train_acc=0.871795    test_loss = 1.719677    test_acc=0.649485
epoch= 93    train_loss = 1.413178    bag_loss = 0.324676    mse_loss = 0.834265 train_acc=0.871795    test_loss = 1.723183    test_acc=0.649485
epoch= 94    train_loss = 1.410477    bag_loss = 0.322454    mse_loss = 0.834004 train_acc=0.871795    test_loss = 1.727388    test_acc=0.649485
epoch= 95    train_loss = 1.407198    bag_loss = 0.319642    mse_loss = 0.833696 train_acc=0.876923    test_loss = 1.730686    test_acc=0.649485
epoch= 96    train_loss = 1.404642    bag_loss = 0.317536    mse_loss = 0.833397 train_acc=0.876923    test_loss = 1.734582    test_acc=0.649485
epoch= 97    train_loss = 1.401675    bag_loss = 0.315047    mse_loss = 0.833034 train_acc=0.876923    test_loss = 1.739735    test_acc=0.649485
epoch= 98    train_loss = 1.398805    bag_loss = 0.312628    mse_loss = 0.832678 train_acc=0.871795    test_loss = 1.743976    test_acc=0.649485
epoch= 99    train_loss = 1.395849    bag_loss = 0.310096    mse_loss = 0.832317 train_acc=0.866667    test_loss = 1.747995    test_acc=0.649485
epoch= 100    train_loss = 1.392780    bag_loss = 0.307471    mse_loss = 0.831912 train_acc=0.871795    test_loss = 1.752799    test_acc=0.649485
epoch= 101    train_loss = 1.389577    bag_loss = 0.304700    mse_loss = 0.831507 train_acc=0.871795    test_loss = 1.757203    test_acc=0.639175
epoch= 102    train_loss = 1.386562    bag_loss = 0.302113    mse_loss = 0.831092 train_acc=0.871795    test_loss = 1.763327    test_acc=0.639175
epoch= 103    train_loss = 1.383348    bag_loss = 0.299328    mse_loss = 0.830644 train_acc=0.882051    test_loss = 1.767714    test_acc=0.639175
epoch= 104    train_loss = 1.380139    bag_loss = 0.296556    mse_loss = 0.830153 train_acc=0.882051    test_loss = 1.772166    test_acc=0.639175
epoch= 105    train_loss = 1.377365    bag_loss = 0.294263    mse_loss = 0.829599 train_acc=0.882051    test_loss = 1.776722    test_acc=0.639175
epoch= 106    train_loss = 1.373857    bag_loss = 0.291267    mse_loss = 0.828997 train_acc=0.882051    test_loss = 1.782513    test_acc=0.639175
epoch= 107    train_loss = 1.370511    bag_loss = 0.288506    mse_loss = 0.828306 train_acc=0.882051    test_loss = 1.787548    test_acc=0.639175
epoch= 108    train_loss = 1.366604    bag_loss = 0.285378    mse_loss = 0.827408 train_acc=0.882051    test_loss = 1.793277    test_acc=0.639175
epoch= 109    train_loss = 1.362171    bag_loss = 0.282442    mse_loss = 0.825754 train_acc=0.887179    test_loss = 1.797078    test_acc=0.639175
epoch= 110    train_loss = 1.357813    bag_loss = 0.279425    mse_loss = 0.824178 train_acc=0.892308    test_loss = 1.803476    test_acc=0.639175
epoch= 111    train_loss = 1.354175    bag_loss = 0.276611    mse_loss = 0.823075 train_acc=0.892308    test_loss = 1.811383    test_acc=0.639175
epoch= 112    train_loss = 1.350325    bag_loss = 0.273399    mse_loss = 0.822125 train_acc=0.902564    test_loss = 1.817709    test_acc=0.639175
epoch= 113    train_loss = 1.346734    bag_loss = 0.270510    mse_loss = 0.821131 train_acc=0.907692    test_loss = 1.826940    test_acc=0.649485
epoch= 114    train_loss = 1.343052    bag_loss = 0.267446    mse_loss = 0.820205 train_acc=0.907692    test_loss = 1.833868    test_acc=0.649485
epoch= 115    train_loss = 1.339138    bag_loss = 0.264238    mse_loss = 0.819157 train_acc=0.917949    test_loss = 1.841752    test_acc=0.649485
epoch= 116    train_loss = 1.335167    bag_loss = 0.261048    mse_loss = 0.818017 train_acc=0.923077    test_loss = 1.849677    test_acc=0.649485
epoch= 117    train_loss = 1.330866    bag_loss = 0.257580    mse_loss = 0.816823 train_acc=0.928205    test_loss = 1.859123    test_acc=0.649485
epoch= 118    train_loss = 1.327485    bag_loss = 0.255012    mse_loss = 0.815625 train_acc=0.933333    test_loss = 1.866029    test_acc=0.649485
epoch= 119    train_loss = 1.322586    bag_loss = 0.251029    mse_loss = 0.814275 train_acc=0.933333    test_loss = 1.873428    test_acc=0.649485
epoch= 120    train_loss = 1.318639    bag_loss = 0.247997    mse_loss = 0.812909 train_acc=0.938462    test_loss = 1.885055    test_acc=0.649485
epoch= 121    train_loss = 1.314013    bag_loss = 0.244322    mse_loss = 0.811488 train_acc=0.938462    test_loss = 1.894697    test_acc=0.649485
epoch= 122    train_loss = 1.309792    bag_loss = 0.241067    mse_loss = 0.810044 train_acc=0.938462    test_loss = 1.900298    test_acc=0.649485
epoch= 123    train_loss = 1.305275    bag_loss = 0.237502    mse_loss = 0.808586 train_acc=0.938462    test_loss = 1.911785    test_acc=0.639175
epoch= 124    train_loss = 1.300816    bag_loss = 0.234078    mse_loss = 0.807025 train_acc=0.938462    test_loss = 1.922307    test_acc=0.649485
epoch= 125    train_loss = 1.295669    bag_loss = 0.229942    mse_loss = 0.805466 train_acc=0.938462    test_loss = 1.933210    test_acc=0.649485
epoch= 126    train_loss = 1.291067    bag_loss = 0.226361    mse_loss = 0.803867 train_acc=0.938462    test_loss = 1.943427    test_acc=0.649485
epoch= 127    train_loss = 1.286264    bag_loss = 0.222621    mse_loss = 0.802210 train_acc=0.938462    test_loss = 1.952844    test_acc=0.639175
epoch= 128    train_loss = 1.281204    bag_loss = 0.218620    mse_loss = 0.800545 train_acc=0.938462    test_loss = 1.963552    test_acc=0.639175
epoch= 129    train_loss = 1.275689    bag_loss = 0.214129    mse_loss = 0.798914 train_acc=0.938462    test_loss = 1.976800    test_acc=0.639175
epoch= 130    train_loss = 1.272035    bag_loss = 0.211612    mse_loss = 0.797138 train_acc=0.938462    test_loss = 1.991369    test_acc=0.639175
epoch= 131    train_loss = 1.267226    bag_loss = 0.207960    mse_loss = 0.795346 train_acc=0.943590    test_loss = 1.999714    test_acc=0.639175
epoch= 132    train_loss = 1.261802    bag_loss = 0.203753    mse_loss = 0.793506 train_acc=0.943590    test_loss = 2.012263    test_acc=0.639175
epoch= 133    train_loss = 1.256633    bag_loss = 0.200301    mse_loss = 0.791199 train_acc=0.943590    test_loss = 2.023432    test_acc=0.628866
epoch= 134    train_loss = 1.251206    bag_loss = 0.196755    mse_loss = 0.788706 train_acc=0.943590    test_loss = 2.035115    test_acc=0.639175
epoch= 135    train_loss = 1.245874    bag_loss = 0.193000    mse_loss = 0.786461 train_acc=0.943590    test_loss = 2.046861    test_acc=0.628866
epoch= 136    train_loss = 1.240544    bag_loss = 0.188895    mse_loss = 0.784578 train_acc=0.943590    test_loss = 2.056324    test_acc=0.628866
epoch= 137    train_loss = 1.236331    bag_loss = 0.185763    mse_loss = 0.782828 train_acc=0.948718    test_loss = 2.068973    test_acc=0.628866
epoch= 138    train_loss = 1.231625    bag_loss = 0.181998    mse_loss = 0.781243 train_acc=0.953846    test_loss = 2.082759    test_acc=0.639175
epoch= 139    train_loss = 1.226981    bag_loss = 0.178174    mse_loss = 0.779806 train_acc=0.948718    test_loss = 2.091335    test_acc=0.639175
epoch= 140    train_loss = 1.222755    bag_loss = 0.174656    mse_loss = 0.778493 train_acc=0.953846    test_loss = 2.105022    test_acc=0.639175
epoch= 141    train_loss = 1.218168    bag_loss = 0.170807    mse_loss = 0.777153 train_acc=0.953846    test_loss = 2.116698    test_acc=0.639175
epoch= 142    train_loss = 1.213923    bag_loss = 0.167201    mse_loss = 0.775921 train_acc=0.953846    test_loss = 2.130878    test_acc=0.639175
epoch= 143    train_loss = 1.210232    bag_loss = 0.164032    mse_loss = 0.774811 train_acc=0.953846    test_loss = 2.146317    test_acc=0.639175
epoch= 144    train_loss = 1.205672    bag_loss = 0.159963    mse_loss = 0.773744 train_acc=0.953846    test_loss = 2.154247    test_acc=0.639175
epoch= 145    train_loss = 1.202071    bag_loss = 0.156735    mse_loss = 0.772808 train_acc=0.958974    test_loss = 2.171415    test_acc=0.639175
epoch= 146    train_loss = 1.197523    bag_loss = 0.152688    mse_loss = 0.771748 train_acc=0.964103    test_loss = 2.186263    test_acc=0.639175
epoch= 147    train_loss = 1.193114    bag_loss = 0.148678    mse_loss = 0.770811 train_acc=0.969231    test_loss = 2.190833    test_acc=0.639175
epoch= 148    train_loss = 1.189375    bag_loss = 0.145359    mse_loss = 0.769895 train_acc=0.969231    test_loss = 2.207278    test_acc=0.639175
epoch= 149    train_loss = 1.185801    bag_loss = 0.142113    mse_loss = 0.769085 train_acc=0.969231    test_loss = 2.216486    test_acc=0.639175
epoch= 150    train_loss = 1.181505    bag_loss = 0.138223    mse_loss = 0.768258 train_acc=0.969231    test_loss = 2.226184    test_acc=0.639175
epoch= 151    train_loss = 1.177978    bag_loss = 0.135114    mse_loss = 0.767423 train_acc=0.974359    test_loss = 2.242433    test_acc=0.639175
epoch= 152    train_loss = 1.175459    bag_loss = 0.132757    mse_loss = 0.766868 train_acc=0.974359    test_loss = 2.254708    test_acc=0.639175
epoch= 153    train_loss = 1.170992    bag_loss = 0.128571    mse_loss = 0.766228 train_acc=0.974359    test_loss = 2.268811    test_acc=0.639175
epoch= 154    train_loss = 1.167374    bag_loss = 0.125206    mse_loss = 0.765609 train_acc=0.974359    test_loss = 2.274134    test_acc=0.639175
epoch= 155    train_loss = 1.164167    bag_loss = 0.122297    mse_loss = 0.764957 train_acc=0.974359    test_loss = 2.289551    test_acc=0.639175
epoch= 156    train_loss = 1.160237    bag_loss = 0.118676    mse_loss = 0.764356 train_acc=0.979487    test_loss = 2.311429    test_acc=0.639175
epoch= 157    train_loss = 1.156640    bag_loss = 0.115275    mse_loss = 0.763872 train_acc=0.984615    test_loss = 2.311966    test_acc=0.639175
epoch= 158    train_loss = 1.155431    bag_loss = 0.114326    mse_loss = 0.763348 train_acc=0.984615    test_loss = 2.331302    test_acc=0.639175
epoch= 159    train_loss = 1.151415    bag_loss = 0.110542    mse_loss = 0.762880 train_acc=0.984615    test_loss = 2.340645    test_acc=0.639175
epoch= 160    train_loss = 1.148634    bag_loss = 0.107989    mse_loss = 0.762447 train_acc=0.984615    test_loss = 2.350233    test_acc=0.639175
epoch= 161    train_loss = 1.146185    bag_loss = 0.105724    mse_loss = 0.762101 train_acc=0.984615    test_loss = 2.359300    test_acc=0.639175
epoch= 162    train_loss = 1.142772    bag_loss = 0.102593    mse_loss = 0.761699 train_acc=0.984615    test_loss = 2.370174    test_acc=0.639175
epoch= 163    train_loss = 1.141361    bag_loss = 0.101451    mse_loss = 0.761316 train_acc=0.989744    test_loss = 2.382479    test_acc=0.639175
epoch= 164    train_loss = 1.138412    bag_loss = 0.098798    mse_loss = 0.760919 train_acc=0.989744    test_loss = 2.384466    test_acc=0.639175
epoch= 165    train_loss = 1.135420    bag_loss = 0.096171    mse_loss = 0.760541 train_acc=0.989744    test_loss = 2.403607    test_acc=0.649485
epoch= 166    train_loss = 1.134427    bag_loss = 0.095529    mse_loss = 0.760140 train_acc=0.989744    test_loss = 2.402370    test_acc=0.639175
epoch= 167    train_loss = 1.132671    bag_loss = 0.094063    mse_loss = 0.759852 train_acc=0.989744    test_loss = 2.420156    test_acc=0.639175
epoch= 168    train_loss = 1.130011    bag_loss = 0.091759    mse_loss = 0.759506 train_acc=0.989744    test_loss = 2.404651    test_acc=0.639175
epoch= 169    train_loss = 1.313769    bag_loss = 0.274861    mse_loss = 0.760816 train_acc=0.943590    test_loss = 2.512013    test_acc=0.628866
epoch= 170    train_loss = 1.149872    bag_loss = 0.111472    mse_loss = 0.761343 train_acc=0.979487    test_loss = 2.335073    test_acc=0.639175
epoch= 171    train_loss = 1.126306    bag_loss = 0.089634    mse_loss = 0.759654 train_acc=0.989744    test_loss = 2.343813    test_acc=0.649485
epoch= 172    train_loss = 1.122735    bag_loss = 0.086670    mse_loss = 0.759077 train_acc=0.989744    test_loss = 2.357594    test_acc=0.649485
epoch= 173    train_loss = 1.120486    bag_loss = 0.084916    mse_loss = 0.758630 train_acc=0.989744    test_loss = 2.366521    test_acc=0.639175
epoch= 174    train_loss = 1.118551    bag_loss = 0.083406    mse_loss = 0.758247 train_acc=0.989744    test_loss = 2.370194    test_acc=0.639175
epoch= 175    train_loss = 1.116992    bag_loss = 0.082299    mse_loss = 0.757888 train_acc=0.989744    test_loss = 2.375553    test_acc=0.628866
epoch= 176    train_loss = 1.115924    bag_loss = 0.081624    mse_loss = 0.757573 train_acc=0.989744    test_loss = 2.376463    test_acc=0.639175
epoch= 177    train_loss = 1.114615    bag_loss = 0.080710    mse_loss = 0.757250 train_acc=0.989744    test_loss = 2.388812    test_acc=0.639175
epoch= 178    train_loss = 1.112869    bag_loss = 0.079290    mse_loss = 0.757007 train_acc=0.989744    test_loss = 2.392672    test_acc=0.639175
epoch= 179    train_loss = 1.111639    bag_loss = 0.078473    mse_loss = 0.756702 train_acc=0.989744    test_loss = 2.406995    test_acc=0.639175
epoch= 180    train_loss = 1.109918    bag_loss = 0.077141    mse_loss = 0.756439 train_acc=0.989744    test_loss = 2.406125    test_acc=0.639175
epoch= 181    train_loss = 1.108972    bag_loss = 0.076552    mse_loss = 0.756221 train_acc=0.989744    test_loss = 2.421258    test_acc=0.639175
epoch= 182    train_loss = 1.107335    bag_loss = 0.075251    mse_loss = 0.756027 train_acc=0.989744    test_loss = 2.432571    test_acc=0.639175
epoch= 183    train_loss = 1.105736    bag_loss = 0.074033    mse_loss = 0.755812 train_acc=0.989744    test_loss = 2.433634    test_acc=0.639175
epoch= 184    train_loss = 1.104328    bag_loss = 0.073073    mse_loss = 0.755548 train_acc=0.989744    test_loss = 2.448416    test_acc=0.639175
epoch= 185    train_loss = 1.103146    bag_loss = 0.072183    mse_loss = 0.755444 train_acc=0.989744    test_loss = 2.443864    test_acc=0.649485
epoch= 186    train_loss = 1.102012    bag_loss = 0.071396    mse_loss = 0.755287 train_acc=0.989744    test_loss = 2.465841    test_acc=0.639175
epoch= 187    train_loss = 1.099732    bag_loss = 0.069526    mse_loss = 0.755090 train_acc=0.989744    test_loss = 2.491153    test_acc=0.639175
epoch= 188    train_loss = 1.098202    bag_loss = 0.068354    mse_loss = 0.754962 train_acc=0.989744    test_loss = 2.516531    test_acc=0.639175
epoch= 189    train_loss = 1.097465    bag_loss = 0.068063    mse_loss = 0.754752 train_acc=0.989744    test_loss = 2.476247    test_acc=0.639175
epoch= 190    train_loss = 1.095192    bag_loss = 0.066303    mse_loss = 0.754486 train_acc=0.989744    test_loss = 2.481759    test_acc=0.639175
epoch= 191    train_loss = 1.094354    bag_loss = 0.065853    mse_loss = 0.754339 train_acc=0.989744    test_loss = 2.534151    test_acc=0.639175
epoch= 192    train_loss = 1.095726    bag_loss = 0.067595    mse_loss = 0.754141 train_acc=0.989744    test_loss = 2.585645    test_acc=0.649485
epoch= 193    train_loss = 1.185432    bag_loss = 0.157676    mse_loss = 0.753967 train_acc=0.958974    test_loss = 2.737739    test_acc=0.649485
epoch= 194    train_loss = 1.464528    bag_loss = 0.436645    mse_loss = 0.757891 train_acc=0.892308    test_loss = 2.307721    test_acc=0.670103
epoch= 195    train_loss = 1.149523    bag_loss = 0.124383    mse_loss = 0.755947 train_acc=0.974359    test_loss = 2.468157    test_acc=0.567010
epoch= 196    train_loss = 1.144729    bag_loss = 0.120143    mse_loss = 0.755865 train_acc=0.974359    test_loss = 2.286680    test_acc=0.659794
epoch= 197    train_loss = 1.091296    bag_loss = 0.067757    mse_loss = 0.754816 train_acc=0.989744    test_loss = 2.303219    test_acc=0.649485
epoch= 198    train_loss = 1.089170    bag_loss = 0.066211    mse_loss = 0.754168 train_acc=0.989744    test_loss = 2.310836    test_acc=0.649485
[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
[0.00016602873802185059, 0.17496463656425476, 0.9998634457588196, 0.4403475522994995, 0.9991751313209534, 0.004245579242706299, 0.18604382872581482, 0.9979098439216614, 0.9724910259246826, 0.9822911024093628, 0.557925820350647, 0.024007648229599, 0.9947736263275146, 0.8656845688819885, 0.014767080545425415, 0.9912490844726562, 0.7301590442657471, 0.9997175931930542, 0.3955250382423401, 0.9960075616836548, 0.999998927116394, 0.9452639818191528, 0.03588104248046875, 0.868727445602417, 0.8404077887535095, 0.9999743700027466, 0.9810563325881958, 0.9978520274162292, 0.3397309482097626, 0.9225320219993591, 0.9977821707725525, 0.9999962449073792, 0.11107984185218811, 0.03933382034301758, 0.9997400641441345, 0.24617800116539001, 0.999966025352478, 0.6468144059181213, 0.9466304779052734, 0.992954671382904, 0.001412719488143921, 0.8967224955558777, 0.1431611180305481, 0.9947466850280762, 0.9960481524467468, 0.9797456860542297, 0.9997000694274902, 0.00354960560798645, 0.06282863020896912, 0.9996769428253174, 0.08885201811790466, 0.7638548612594604, 0.737032949924469, 0.7367111444473267, 0.9987775087356567, 0.014091581106185913, 0.9984918236732483, 0.8932814002037048, 0.7168490886688232, 0.027419477701187134, 0.722792387008667, 0.043517887592315674, 0.9987602233886719, 0.9897443056106567, 0.9924095869064331, 0.9676477909088135, 0.9969471096992493, 0.573762834072113, 0.003290325403213501, 0.4265698194503784, 0.05881631374359131, 0.9999916553497314, 0.9384965300559998, 0.9687499403953552, 0.9864548444747925, 0.02567097544670105, 0.9652894735336304, 0.021456271409988403, 0.9968492388725281, 0.8334363102912903, 0.990281343460083, 0.7450619339942932, 0.9364770650863647, 0.8133980631828308, 0.039688169956207275, 0.10766837000846863, 0.9601170420646667, 0.982288658618927, 0.7781803607940674, 0.0019186437129974365, 0.6791790127754211, 0.9963842034339905, 0.999958872795105, 0.005838155746459961, 0.9984009265899658, 0.5011076927185059, 0.940960705280304]
epoch= 199    train_loss = 1.087442    bag_loss = 0.064892    mse_loss = 0.753723 train_acc=0.989744    test_loss = 2.320578    test_acc=0.649485
Ground truth: [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], Predicted: [0.00016602873802185059, 0.17496463656425476, 0.9998634457588196, 0.4403475522994995, 0.9991751313209534, 0.004245579242706299, 0.18604382872581482, 0.9979098439216614, 0.9724910259246826, 0.9822911024093628, 0.557925820350647, 0.024007648229599, 0.9947736263275146, 0.8656845688819885, 0.014767080545425415, 0.9912490844726562, 0.7301590442657471, 0.9997175931930542, 0.3955250382423401, 0.9960075616836548, 0.999998927116394, 0.9452639818191528, 0.03588104248046875, 0.868727445602417, 0.8404077887535095, 0.9999743700027466, 0.9810563325881958, 0.9978520274162292, 0.3397309482097626, 0.9225320219993591, 0.9977821707725525, 0.9999962449073792, 0.11107984185218811, 0.03933382034301758, 0.9997400641441345, 0.24617800116539001, 0.999966025352478, 0.6468144059181213, 0.9466304779052734, 0.992954671382904, 0.001412719488143921, 0.8967224955558777, 0.1431611180305481, 0.9947466850280762, 0.9960481524467468, 0.9797456860542297, 0.9997000694274902, 0.00354960560798645, 0.06282863020896912, 0.9996769428253174, 0.08885201811790466, 0.7638548612594604, 0.737032949924469, 0.7367111444473267, 0.9987775087356567, 0.014091581106185913, 0.9984918236732483, 0.8932814002037048, 0.7168490886688232, 0.027419477701187134, 0.722792387008667, 0.043517887592315674, 0.9987602233886719, 0.9897443056106567, 0.9924095869064331, 0.9676477909088135, 0.9969471096992493, 0.573762834072113, 0.003290325403213501, 0.4265698194503784, 0.05881631374359131, 0.9999916553497314, 0.9384965300559998, 0.9687499403953552, 0.9864548444747925, 0.02567097544670105, 0.9652894735336304, 0.021456271409988403, 0.9968492388725281, 0.8334363102912903, 0.990281343460083, 0.7450619339942932, 0.9364770650863647, 0.8133980631828308, 0.039688169956207275, 0.10766837000846863, 0.9601170420646667, 0.982288658618927, 0.7781803607940674, 0.0019186437129974365, 0.6791790127754211, 0.9963842034339905, 0.999958872795105, 0.005838155746459961, 0.9984009265899658, 0.5011076927185059, 0.940960705280304]
Runs: 0, Training fold:1
AUC =  0.6227824463118581
epoch= 0    train_loss = 3.420739    bag_loss = 0.715789    mse_loss = 1.252902 train_acc=0.374359    test_loss = 3.282754    test_acc=0.484536
epoch= 1    train_loss = 3.216334    bag_loss = 0.683559    mse_loss = 1.223506 train_acc=0.676923    test_loss = 3.089582    test_acc=0.690722
epoch= 2    train_loss = 2.969032    bag_loss = 0.665470    mse_loss = 1.115107 train_acc=0.712821    test_loss = 2.840551    test_acc=0.731959
epoch= 3    train_loss = 2.735028    bag_loss = 0.637782    mse_loss = 1.007126 train_acc=0.723077    test_loss = 2.665000    test_acc=0.721649
epoch= 4    train_loss = 2.576703    bag_loss = 0.595915    mse_loss = 0.974647 train_acc=0.728205    test_loss = 2.534990    test_acc=0.721649
epoch= 5    train_loss = 2.458220    bag_loss = 0.563819    mse_loss = 0.958103 train_acc=0.748718    test_loss = 2.440585    test_acc=0.731959
epoch= 6    train_loss = 2.370970    bag_loss = 0.545871    mse_loss = 0.947236 train_acc=0.748718    test_loss = 2.371525    test_acc=0.721649
epoch= 7    train_loss = 2.301767    bag_loss = 0.534901    mse_loss = 0.938699 train_acc=0.758974    test_loss = 2.314179    test_acc=0.721649
epoch= 8    train_loss = 2.241530    bag_loss = 0.526275    mse_loss = 0.929810 train_acc=0.764103    test_loss = 2.262150    test_acc=0.731959
epoch= 9    train_loss = 2.187828    bag_loss = 0.519765    mse_loss = 0.919362 train_acc=0.764103    test_loss = 2.214064    test_acc=0.742268
epoch= 10    train_loss = 2.136519    bag_loss = 0.514080    mse_loss = 0.905285 train_acc=0.758974    test_loss = 2.166626    test_acc=0.762887
epoch= 11    train_loss = 2.086264    bag_loss = 0.509523    mse_loss = 0.886510 train_acc=0.753846    test_loss = 2.119506    test_acc=0.762887
epoch= 12    train_loss = 2.039901    bag_loss = 0.505656    mse_loss = 0.867194 train_acc=0.753846    test_loss = 2.080178    test_acc=0.742268
epoch= 13    train_loss = 2.000598    bag_loss = 0.502497    mse_loss = 0.851653 train_acc=0.764103    test_loss = 2.045213    test_acc=0.731959
epoch= 14    train_loss = 1.968273    bag_loss = 0.498967    mse_loss = 0.841476 train_acc=0.764103    test_loss = 2.019283    test_acc=0.731959
epoch= 15    train_loss = 1.941293    bag_loss = 0.495935    mse_loss = 0.834515 train_acc=0.764103    test_loss = 1.992333    test_acc=0.731959
epoch= 16    train_loss = 1.917406    bag_loss = 0.492079    mse_loss = 0.829944 train_acc=0.769231    test_loss = 1.973077    test_acc=0.731959
epoch= 17    train_loss = 1.896331    bag_loss = 0.488693    mse_loss = 0.826410 train_acc=0.769231    test_loss = 1.955455    test_acc=0.731959
epoch= 18    train_loss = 1.877259    bag_loss = 0.485148    mse_loss = 0.823864 train_acc=0.769231    test_loss = 1.939702    test_acc=0.731959
epoch= 19    train_loss = 1.859580    bag_loss = 0.481515    mse_loss = 0.821733 train_acc=0.774359    test_loss = 1.923434    test_acc=0.731959
epoch= 20    train_loss = 1.841965    bag_loss = 0.478099    mse_loss = 0.818449 train_acc=0.784615    test_loss = 1.910507    test_acc=0.731959
epoch= 21    train_loss = 1.826694    bag_loss = 0.474665    mse_loss = 0.816637 train_acc=0.789744    test_loss = 1.898616    test_acc=0.742268
epoch= 22    train_loss = 1.812359    bag_loss = 0.470784    mse_loss = 0.815472 train_acc=0.784615    test_loss = 1.886962    test_acc=0.742268
epoch= 23    train_loss = 1.799172    bag_loss = 0.467235    mse_loss = 0.814416 train_acc=0.789744    test_loss = 1.878078    test_acc=0.742268
epoch= 24    train_loss = 1.786512    bag_loss = 0.463459    mse_loss = 0.813542 train_acc=0.789744    test_loss = 1.868795    test_acc=0.742268
epoch= 25    train_loss = 1.774449    bag_loss = 0.459630    mse_loss = 0.812757 train_acc=0.800000    test_loss = 1.857123    test_acc=0.742268
epoch= 26    train_loss = 1.762778    bag_loss = 0.455494    mse_loss = 0.812089 train_acc=0.800000    test_loss = 1.852124    test_acc=0.742268
epoch= 27    train_loss = 1.751693    bag_loss = 0.451564    mse_loss = 0.811406 train_acc=0.805128    test_loss = 1.845581    test_acc=0.731959
epoch= 28    train_loss = 1.740879    bag_loss = 0.447387    mse_loss = 0.810797 train_acc=0.800000    test_loss = 1.836956    test_acc=0.731959
epoch= 29    train_loss = 1.730567    bag_loss = 0.443236    mse_loss = 0.810216 train_acc=0.800000    test_loss = 1.834171    test_acc=0.731959
epoch= 30    train_loss = 1.720587    bag_loss = 0.439095    mse_loss = 0.809656 train_acc=0.805128    test_loss = 1.829975    test_acc=0.731959
epoch= 31    train_loss = 1.710748    bag_loss = 0.434705    mse_loss = 0.809130 train_acc=0.815385    test_loss = 1.822327    test_acc=0.731959
epoch= 32    train_loss = 1.700754    bag_loss = 0.430212    mse_loss = 0.808158 train_acc=0.815385    test_loss = 1.820094    test_acc=0.731959
epoch= 33    train_loss = 1.689310    bag_loss = 0.425279    mse_loss = 0.805849 train_acc=0.820513    test_loss = 1.813019    test_acc=0.731959
epoch= 34    train_loss = 1.678552    bag_loss = 0.420571    mse_loss = 0.803620 train_acc=0.820513    test_loss = 1.812020    test_acc=0.731959
epoch= 35    train_loss = 1.669420    bag_loss = 0.415747    mse_loss = 0.802907 train_acc=0.820513    test_loss = 1.807484    test_acc=0.742268
epoch= 36    train_loss = 1.660629    bag_loss = 0.410994    mse_loss = 0.802208 train_acc=0.820513    test_loss = 1.807441    test_acc=0.742268
epoch= 37    train_loss = 1.651968    bag_loss = 0.406005    mse_loss = 0.801689 train_acc=0.815385    test_loss = 1.805840    test_acc=0.742268
epoch= 38    train_loss = 1.643072    bag_loss = 0.400550    mse_loss = 0.801160 train_acc=0.820513    test_loss = 1.803298    test_acc=0.731959
epoch= 39    train_loss = 1.634813    bag_loss = 0.395439    mse_loss = 0.800678 train_acc=0.820513    test_loss = 1.806059    test_acc=0.731959
epoch= 40    train_loss = 1.626319    bag_loss = 0.389883    mse_loss = 0.800271 train_acc=0.815385    test_loss = 1.806387    test_acc=0.731959
epoch= 41    train_loss = 1.617471    bag_loss = 0.383743    mse_loss = 0.799884 train_acc=0.815385    test_loss = 1.806299    test_acc=0.742268
epoch= 42    train_loss = 1.609441    bag_loss = 0.378366    mse_loss = 0.799383 train_acc=0.820513    test_loss = 1.810642    test_acc=0.742268
epoch= 43    train_loss = 1.599811    bag_loss = 0.372214    mse_loss = 0.797965 train_acc=0.825641    test_loss = 1.813670    test_acc=0.742268
epoch= 44    train_loss = 1.590349    bag_loss = 0.365857    mse_loss = 0.796671 train_acc=0.830769    test_loss = 1.812416    test_acc=0.731959
epoch= 45    train_loss = 1.583201    bag_loss = 0.360844    mse_loss = 0.796203 train_acc=0.835897    test_loss = 1.818779    test_acc=0.731959
epoch= 46    train_loss = 1.575134    bag_loss = 0.354596    mse_loss = 0.795979 train_acc=0.841026    test_loss = 1.825041    test_acc=0.731959
epoch= 47    train_loss = 1.567060    bag_loss = 0.348307    mse_loss = 0.795673 train_acc=0.846154    test_loss = 1.826220    test_acc=0.731959
epoch= 48    train_loss = 1.559662    bag_loss = 0.342540    mse_loss = 0.795390 train_acc=0.861538    test_loss = 1.835226    test_acc=0.731959
epoch= 49    train_loss = 1.551476    bag_loss = 0.335893    mse_loss = 0.795131 train_acc=0.861538    test_loss = 1.840325    test_acc=0.721649
epoch= 50    train_loss = 1.543765    bag_loss = 0.329629    mse_loss = 0.794882 train_acc=0.866667    test_loss = 1.842621    test_acc=0.731959
epoch= 51    train_loss = 1.536692    bag_loss = 0.323862    mse_loss = 0.794654 train_acc=0.866667    test_loss = 1.853704    test_acc=0.711340
epoch= 52    train_loss = 1.528368    bag_loss = 0.316910    mse_loss = 0.794312 train_acc=0.882051    test_loss = 1.860284    test_acc=0.701031
epoch= 53    train_loss = 1.519994    bag_loss = 0.310549    mse_loss = 0.793280 train_acc=0.882051    test_loss = 1.863364    test_acc=0.701031
epoch= 54    train_loss = 1.511612    bag_loss = 0.304601    mse_loss = 0.791677 train_acc=0.887179    test_loss = 1.874195    test_acc=0.701031
epoch= 55    train_loss = 1.503713    bag_loss = 0.298045    mse_loss = 0.791075 train_acc=0.897436    test_loss = 1.881940    test_acc=0.701031
epoch= 56    train_loss = 1.495666    bag_loss = 0.291050    mse_loss = 0.790689 train_acc=0.897436    test_loss = 1.885554    test_acc=0.711340
epoch= 57    train_loss = 1.488483    bag_loss = 0.284714    mse_loss = 0.790440 train_acc=0.902564    test_loss = 1.898948    test_acc=0.701031
epoch= 58    train_loss = 1.480622    bag_loss = 0.277755    mse_loss = 0.790116 train_acc=0.907692    test_loss = 1.904575    test_acc=0.711340
epoch= 59    train_loss = 1.473674    bag_loss = 0.271560    mse_loss = 0.789890 train_acc=0.907692    test_loss = 1.919071    test_acc=0.701031
epoch= 60    train_loss = 1.465864    bag_loss = 0.264471    mse_loss = 0.789671 train_acc=0.923077    test_loss = 1.925798    test_acc=0.711340
epoch= 61    train_loss = 1.459240    bag_loss = 0.258476    mse_loss = 0.789478 train_acc=0.933333    test_loss = 1.938817    test_acc=0.711340
epoch= 62    train_loss = 1.451548    bag_loss = 0.251393    mse_loss = 0.789289 train_acc=0.933333    test_loss = 1.945493    test_acc=0.711340
epoch= 63    train_loss = 1.445299    bag_loss = 0.245691    mse_loss = 0.789079 train_acc=0.928205    test_loss = 1.961189    test_acc=0.711340
epoch= 64    train_loss = 1.438415    bag_loss = 0.239357    mse_loss = 0.788896 train_acc=0.933333    test_loss = 1.970557    test_acc=0.711340
epoch= 65    train_loss = 1.431673    bag_loss = 0.233086    mse_loss = 0.788752 train_acc=0.928205    test_loss = 1.985583    test_acc=0.701031
epoch= 66    train_loss = 1.424885    bag_loss = 0.226760    mse_loss = 0.788605 train_acc=0.933333    test_loss = 1.995902    test_acc=0.701031
epoch= 67    train_loss = 1.418522    bag_loss = 0.220814    mse_loss = 0.788459 train_acc=0.933333    test_loss = 2.010064    test_acc=0.690722
epoch= 68    train_loss = 1.411578    bag_loss = 0.214269    mse_loss = 0.788314 train_acc=0.938462    test_loss = 2.023882    test_acc=0.690722
epoch= 69    train_loss = 1.405050    bag_loss = 0.208132    mse_loss = 0.788159 train_acc=0.938462    test_loss = 2.035955    test_acc=0.690722
epoch= 70    train_loss = 1.398577    bag_loss = 0.201999    mse_loss = 0.788020 train_acc=0.938462    test_loss = 2.050531    test_acc=0.690722
epoch= 71    train_loss = 1.392189    bag_loss = 0.195953    mse_loss = 0.787868 train_acc=0.933333    test_loss = 2.064126    test_acc=0.690722
epoch= 72    train_loss = 1.385737    bag_loss = 0.189800    mse_loss = 0.787719 train_acc=0.933333    test_loss = 2.078046    test_acc=0.690722
epoch= 73    train_loss = 1.380019    bag_loss = 0.184375    mse_loss = 0.787569 train_acc=0.933333    test_loss = 2.092488    test_acc=0.690722
epoch= 74    train_loss = 1.373765    bag_loss = 0.178414    mse_loss = 0.787417 train_acc=0.943590    test_loss = 2.107304    test_acc=0.680412
epoch= 75    train_loss = 1.367660    bag_loss = 0.172563    mse_loss = 0.787282 train_acc=0.948718    test_loss = 2.120750    test_acc=0.659794
epoch= 76    train_loss = 1.361537    bag_loss = 0.166744    mse_loss = 0.787073 train_acc=0.948718    test_loss = 2.135289    test_acc=0.670103
epoch= 77    train_loss = 1.355464    bag_loss = 0.160899    mse_loss = 0.786941 train_acc=0.958974    test_loss = 2.151645    test_acc=0.670103
epoch= 78    train_loss = 1.348981    bag_loss = 0.154696    mse_loss = 0.786728 train_acc=0.964103    test_loss = 2.166933    test_acc=0.659794
epoch= 79    train_loss = 1.343538    bag_loss = 0.149526    mse_loss = 0.786525 train_acc=0.969231    test_loss = 2.186021    test_acc=0.659794
epoch= 80    train_loss = 1.338060    bag_loss = 0.144280    mse_loss = 0.786350 train_acc=0.974359    test_loss = 2.200997    test_acc=0.659794
epoch= 81    train_loss = 1.331938    bag_loss = 0.138396    mse_loss = 0.786146 train_acc=0.974359    test_loss = 2.221317    test_acc=0.659794
epoch= 82    train_loss = 1.326168    bag_loss = 0.132847    mse_loss = 0.785958 train_acc=0.974359    test_loss = 2.239306    test_acc=0.659794
epoch= 83    train_loss = 1.320948    bag_loss = 0.127886    mse_loss = 0.785734 train_acc=0.974359    test_loss = 2.257028    test_acc=0.649485
epoch= 84    train_loss = 1.315529    bag_loss = 0.122684    mse_loss = 0.785556 train_acc=0.979487    test_loss = 2.277850    test_acc=0.649485
epoch= 85    train_loss = 1.309351    bag_loss = 0.116721    mse_loss = 0.785380 train_acc=0.979487    test_loss = 2.299807    test_acc=0.649485
epoch= 86    train_loss = 1.304907    bag_loss = 0.112540    mse_loss = 0.785169 train_acc=0.979487    test_loss = 2.316327    test_acc=0.639175
epoch= 87    train_loss = 1.299919    bag_loss = 0.107833    mse_loss = 0.784947 train_acc=0.979487    test_loss = 2.333894    test_acc=0.639175
epoch= 88    train_loss = 1.294683    bag_loss = 0.102818    mse_loss = 0.784759 train_acc=0.979487    test_loss = 2.361883    test_acc=0.628866
epoch= 89    train_loss = 1.289977    bag_loss = 0.098455    mse_loss = 0.784518 train_acc=0.979487    test_loss = 2.378542    test_acc=0.628866
epoch= 90    train_loss = 1.284391    bag_loss = 0.093168    mse_loss = 0.784298 train_acc=0.979487    test_loss = 2.403256    test_acc=0.618557
epoch= 91    train_loss = 1.280281    bag_loss = 0.089451    mse_loss = 0.784023 train_acc=0.979487    test_loss = 2.423105    test_acc=0.628866
epoch= 92    train_loss = 1.276166    bag_loss = 0.085695    mse_loss = 0.783793 train_acc=0.979487    test_loss = 2.445626    test_acc=0.628866
epoch= 93    train_loss = 1.271460    bag_loss = 0.081392    mse_loss = 0.783529 train_acc=0.979487    test_loss = 2.468322    test_acc=0.618557
epoch= 94    train_loss = 1.266929    bag_loss = 0.077309    mse_loss = 0.783244 train_acc=0.984615    test_loss = 2.488374    test_acc=0.628866
epoch= 95    train_loss = 1.263169    bag_loss = 0.074033    mse_loss = 0.782951 train_acc=0.984615    test_loss = 2.513763    test_acc=0.618557
epoch= 96    train_loss = 1.259594    bag_loss = 0.070997    mse_loss = 0.782621 train_acc=0.989744    test_loss = 2.530543    test_acc=0.628866
epoch= 97    train_loss = 1.254835    bag_loss = 0.066750    mse_loss = 0.782311 train_acc=0.989744    test_loss = 2.564293    test_acc=0.628866
epoch= 98    train_loss = 1.250965    bag_loss = 0.063570    mse_loss = 0.781906 train_acc=0.989744    test_loss = 2.582082    test_acc=0.628866
epoch= 99    train_loss = 1.247234    bag_loss = 0.060477    mse_loss = 0.781559 train_acc=0.994872    test_loss = 2.605043    test_acc=0.628866
epoch= 100    train_loss = 1.243415    bag_loss = 0.057385    mse_loss = 0.781152 train_acc=0.994872    test_loss = 2.631361    test_acc=0.608247
epoch= 101    train_loss = 1.239156    bag_loss = 0.053946    mse_loss = 0.780701 train_acc=0.994872    test_loss = 2.650290    test_acc=0.618557
epoch= 102    train_loss = 1.235672    bag_loss = 0.051294    mse_loss = 0.780275 train_acc=0.994872    test_loss = 2.667977    test_acc=0.618557
epoch= 103    train_loss = 1.232441    bag_loss = 0.049031    mse_loss = 0.779759 train_acc=0.994872    test_loss = 2.685403    test_acc=0.618557
epoch= 104    train_loss = 1.228748    bag_loss = 0.046348    mse_loss = 0.779217 train_acc=0.994872    test_loss = 2.708104    test_acc=0.608247
epoch= 105    train_loss = 1.226083    bag_loss = 0.044752    mse_loss = 0.778663 train_acc=0.994872    test_loss = 2.723949    test_acc=0.608247
epoch= 106    train_loss = 1.222625    bag_loss = 0.042374    mse_loss = 0.778104 train_acc=0.994872    test_loss = 2.745189    test_acc=0.608247
epoch= 107    train_loss = 1.218800    bag_loss = 0.039770    mse_loss = 0.777448 train_acc=0.994872    test_loss = 2.771036    test_acc=0.608247
epoch= 108    train_loss = 1.216052    bag_loss = 0.038371    mse_loss = 0.776751 train_acc=0.994872    test_loss = 2.776830    test_acc=0.608247
epoch= 109    train_loss = 1.212374    bag_loss = 0.036082    mse_loss = 0.776015 train_acc=1.000000    test_loss = 2.794939    test_acc=0.608247
epoch= 110    train_loss = 1.208919    bag_loss = 0.034110    mse_loss = 0.775246 train_acc=1.000000    test_loss = 2.801061    test_acc=0.608247
epoch= 111    train_loss = 1.206249    bag_loss = 0.033000    mse_loss = 0.774443 train_acc=1.000000    test_loss = 2.831615    test_acc=0.608247
epoch= 112    train_loss = 1.202861    bag_loss = 0.031349    mse_loss = 0.773522 train_acc=1.000000    test_loss = 2.838680    test_acc=0.608247
epoch= 113    train_loss = 1.199337    bag_loss = 0.029624    mse_loss = 0.772576 train_acc=1.000000    test_loss = 2.857116    test_acc=0.608247
epoch= 114    train_loss = 1.196039    bag_loss = 0.028331    mse_loss = 0.771500 train_acc=1.000000    test_loss = 2.862210    test_acc=0.608247
epoch= 115    train_loss = 1.193669    bag_loss = 0.027986    mse_loss = 0.770392 train_acc=1.000000    test_loss = 2.878171    test_acc=0.618557
epoch= 116    train_loss = 1.192138    bag_loss = 0.028450    mse_loss = 0.769285 train_acc=1.000000    test_loss = 2.866265    test_acc=0.608247
epoch= 117    train_loss = 1.188556    bag_loss = 0.026927    mse_loss = 0.768122 train_acc=1.000000    test_loss = 2.910402    test_acc=0.628866
epoch= 118    train_loss = 1.192553    bag_loss = 0.032940    mse_loss = 0.766927 train_acc=1.000000    test_loss = 2.850708    test_acc=0.608247
epoch= 119    train_loss = 1.318364    bag_loss = 0.160616    mse_loss = 0.766214 train_acc=0.953846    test_loss = 2.770504    test_acc=0.659794
epoch= 120    train_loss = 1.308462    bag_loss = 0.152555    mse_loss = 0.765920 train_acc=0.953846    test_loss = 2.780134    test_acc=0.639175
epoch= 121    train_loss = 1.200676    bag_loss = 0.045543    mse_loss = 0.765376 train_acc=0.994872    test_loss = 2.803628    test_acc=0.608247
epoch= 122    train_loss = 1.187671    bag_loss = 0.033796    mse_loss = 0.764146 train_acc=1.000000    test_loss = 2.793311    test_acc=0.608247
epoch= 123    train_loss = 1.176247    bag_loss = 0.023710    mse_loss = 0.762934 train_acc=1.000000    test_loss = 2.805982    test_acc=0.608247
epoch= 124    train_loss = 1.173332    bag_loss = 0.022314    mse_loss = 0.761654 train_acc=1.000000    test_loss = 2.803185    test_acc=0.618557
epoch= 125    train_loss = 1.170885    bag_loss = 0.021483    mse_loss = 0.760330 train_acc=1.000000    test_loss = 2.800401    test_acc=0.608247
epoch= 126    train_loss = 1.168523    bag_loss = 0.020823    mse_loss = 0.758973 train_acc=1.000000    test_loss = 2.799198    test_acc=0.608247
epoch= 127    train_loss = 1.166184    bag_loss = 0.020280    mse_loss = 0.757580 train_acc=1.000000    test_loss = 2.795510    test_acc=0.597938
epoch= 128    train_loss = 1.163808    bag_loss = 0.019782    mse_loss = 0.756158 train_acc=1.000000    test_loss = 2.796733    test_acc=0.597938
epoch= 129    train_loss = 1.161405    bag_loss = 0.019345    mse_loss = 0.754715 train_acc=1.000000    test_loss = 2.792884    test_acc=0.608247
epoch= 130    train_loss = 1.159079    bag_loss = 0.019064    mse_loss = 0.753247 train_acc=1.000000    test_loss = 2.790473    test_acc=0.597938
epoch= 131    train_loss = 1.156616    bag_loss = 0.018712    mse_loss = 0.751782 train_acc=1.000000    test_loss = 2.789197    test_acc=0.597938
epoch= 132    train_loss = 1.154224    bag_loss = 0.018513    mse_loss = 0.750300 train_acc=1.000000    test_loss = 2.789019    test_acc=0.597938
epoch= 133    train_loss = 1.151683    bag_loss = 0.018226    mse_loss = 0.748825 train_acc=1.000000    test_loss = 2.791728    test_acc=0.597938
epoch= 134    train_loss = 1.149162    bag_loss = 0.018006    mse_loss = 0.747375 train_acc=1.000000    test_loss = 2.790313    test_acc=0.608247
epoch= 135    train_loss = 1.146586    bag_loss = 0.017790    mse_loss = 0.745935 train_acc=1.000000    test_loss = 2.793819    test_acc=0.608247
epoch= 136    train_loss = 1.144150    bag_loss = 0.017754    mse_loss = 0.744531 train_acc=1.000000    test_loss = 2.795557    test_acc=0.608247
epoch= 137    train_loss = 1.141638    bag_loss = 0.017659    mse_loss = 0.743172 train_acc=1.000000    test_loss = 2.798619    test_acc=0.608247
epoch= 138    train_loss = 1.138866    bag_loss = 0.017341    mse_loss = 0.741853 train_acc=1.000000    test_loss = 2.796959    test_acc=0.608247
epoch= 139    train_loss = 1.136248    bag_loss = 0.017204    mse_loss = 0.740570 train_acc=1.000000    test_loss = 2.808587    test_acc=0.608247
epoch= 140    train_loss = 1.133750    bag_loss = 0.017267    mse_loss = 0.739301 train_acc=1.000000    test_loss = 2.798666    test_acc=0.608247
epoch= 141    train_loss = 1.130769    bag_loss = 0.016822    mse_loss = 0.738087 train_acc=1.000000    test_loss = 2.814212    test_acc=0.608247
epoch= 142    train_loss = 1.128040    bag_loss = 0.016729    mse_loss = 0.736873 train_acc=1.000000    test_loss = 2.801868    test_acc=0.608247
epoch= 143    train_loss = 1.125371    bag_loss = 0.016645    mse_loss = 0.735736 train_acc=1.000000    test_loss = 2.802619    test_acc=0.608247
epoch= 144    train_loss = 1.122299    bag_loss = 0.016176    mse_loss = 0.734659 train_acc=1.000000    test_loss = 2.805031    test_acc=0.597938
epoch= 145    train_loss = 1.119733    bag_loss = 0.016251    mse_loss = 0.733592 train_acc=1.000000    test_loss = 2.801719    test_acc=0.608247
epoch= 146    train_loss = 1.117128    bag_loss = 0.016216    mse_loss = 0.732622 train_acc=1.000000    test_loss = 2.798866    test_acc=0.608247
epoch= 147    train_loss = 1.115020    bag_loss = 0.016641    mse_loss = 0.731662 train_acc=1.000000    test_loss = 2.792309    test_acc=0.639175
epoch= 148    train_loss = 1.113385    bag_loss = 0.017374    mse_loss = 0.730817 train_acc=1.000000    test_loss = 2.808024    test_acc=0.628866
epoch= 149    train_loss = 1.112408    bag_loss = 0.018506    mse_loss = 0.730039 train_acc=1.000000    test_loss = 2.802138    test_acc=0.628866
epoch= 150    train_loss = 1.211173    bag_loss = 0.118962    mse_loss = 0.729368 train_acc=0.974359    test_loss = 2.765573    test_acc=0.587629
epoch= 151    train_loss = 1.316056    bag_loss = 0.225688    mse_loss = 0.729335 train_acc=0.958974    test_loss = 3.020393    test_acc=0.567010
epoch= 152    train_loss = 1.148133    bag_loss = 0.058876    mse_loss = 0.728874 train_acc=0.989744    test_loss = 2.769196    test_acc=0.608247
epoch= 153    train_loss = 1.105300    bag_loss = 0.017087    mse_loss = 0.728041 train_acc=1.000000    test_loss = 2.780215    test_acc=0.618557
epoch= 154    train_loss = 1.103098    bag_loss = 0.015766    mse_loss = 0.727414 train_acc=1.000000    test_loss = 2.777440    test_acc=0.618557
epoch= 155    train_loss = 1.101463    bag_loss = 0.015041    mse_loss = 0.726830 train_acc=1.000000    test_loss = 2.774018    test_acc=0.618557
epoch= 156    train_loss = 1.100045    bag_loss = 0.014562    mse_loss = 0.726277 train_acc=1.000000    test_loss = 2.769642    test_acc=0.618557
epoch= 157    train_loss = 1.098692    bag_loss = 0.014179    mse_loss = 0.725756 train_acc=1.000000    test_loss = 2.766674    test_acc=0.618557
epoch= 158    train_loss = 1.097402    bag_loss = 0.013887    mse_loss = 0.725266 train_acc=1.000000    test_loss = 2.764372    test_acc=0.618557
epoch= 159    train_loss = 1.096174    bag_loss = 0.013696    mse_loss = 0.724797 train_acc=1.000000    test_loss = 2.759321    test_acc=0.608247
epoch= 160    train_loss = 1.094935    bag_loss = 0.013536    mse_loss = 0.724346 train_acc=1.000000    test_loss = 2.757860    test_acc=0.597938
epoch= 161    train_loss = 1.093683    bag_loss = 0.013416    mse_loss = 0.723900 train_acc=1.000000    test_loss = 2.753123    test_acc=0.597938
epoch= 162    train_loss = 1.092419    bag_loss = 0.013343    mse_loss = 0.723457 train_acc=1.000000    test_loss = 2.749468    test_acc=0.597938
epoch= 163    train_loss = 1.091121    bag_loss = 0.013297    mse_loss = 0.723011 train_acc=1.000000    test_loss = 2.746823    test_acc=0.597938
epoch= 164    train_loss = 1.089846    bag_loss = 0.013316    mse_loss = 0.722582 train_acc=1.000000    test_loss = 2.744045    test_acc=0.608247
epoch= 165    train_loss = 1.088520    bag_loss = 0.013343    mse_loss = 0.722152 train_acc=1.000000    test_loss = 2.739750    test_acc=0.608247
epoch= 166    train_loss = 1.087080    bag_loss = 0.013312    mse_loss = 0.721722 train_acc=1.000000    test_loss = 2.739264    test_acc=0.597938
epoch= 167    train_loss = 1.085705    bag_loss = 0.013400    mse_loss = 0.721300 train_acc=1.000000    test_loss = 2.732689    test_acc=0.618557
epoch= 168    train_loss = 1.084192    bag_loss = 0.013410    mse_loss = 0.720871 train_acc=1.000000    test_loss = 2.726693    test_acc=0.608247
epoch= 169    train_loss = 1.082714    bag_loss = 0.013472    mse_loss = 0.720475 train_acc=1.000000    test_loss = 2.719713    test_acc=0.597938
epoch= 170    train_loss = 1.081130    bag_loss = 0.013454    mse_loss = 0.720089 train_acc=1.000000    test_loss = 2.724830    test_acc=0.608247
epoch= 171    train_loss = 1.079423    bag_loss = 0.013383    mse_loss = 0.719717 train_acc=1.000000    test_loss = 2.715788    test_acc=0.608247
epoch= 172    train_loss = 1.077866    bag_loss = 0.013487    mse_loss = 0.719353 train_acc=1.000000    test_loss = 2.716403    test_acc=0.608247
epoch= 173    train_loss = 1.076022    bag_loss = 0.013341    mse_loss = 0.718998 train_acc=1.000000    test_loss = 2.710508    test_acc=0.618557
epoch= 174    train_loss = 1.074526    bag_loss = 0.013542    mse_loss = 0.718668 train_acc=1.000000    test_loss = 2.716692    test_acc=0.628866
epoch= 175    train_loss = 1.072602    bag_loss = 0.013409    mse_loss = 0.718328 train_acc=1.000000    test_loss = 2.706158    test_acc=0.628866
epoch= 176    train_loss = 1.070963    bag_loss = 0.013515    mse_loss = 0.718031 train_acc=1.000000    test_loss = 2.709408    test_acc=0.618557
epoch= 177    train_loss = 1.068964    bag_loss = 0.013285    mse_loss = 0.717721 train_acc=1.000000    test_loss = 2.715754    test_acc=0.639175
epoch= 178    train_loss = 1.067097    bag_loss = 0.013269    mse_loss = 0.717437 train_acc=1.000000    test_loss = 2.703859    test_acc=0.639175
epoch= 179    train_loss = 1.065165    bag_loss = 0.013161    mse_loss = 0.717167 train_acc=1.000000    test_loss = 2.711034    test_acc=0.628866
epoch= 180    train_loss = 1.063668    bag_loss = 0.013465    mse_loss = 0.716889 train_acc=1.000000    test_loss = 2.713710    test_acc=0.639175
epoch= 181    train_loss = 1.061385    bag_loss = 0.013047    mse_loss = 0.716609 train_acc=1.000000    test_loss = 2.708779    test_acc=0.649485
epoch= 182    train_loss = 1.059789    bag_loss = 0.013241    mse_loss = 0.716383 train_acc=1.000000    test_loss = 2.721826    test_acc=0.649485
epoch= 183    train_loss = 1.057697    bag_loss = 0.013030    mse_loss = 0.716110 train_acc=1.000000    test_loss = 2.724134    test_acc=0.639175
epoch= 184    train_loss = 1.057798    bag_loss = 0.014836    mse_loss = 0.715858 train_acc=1.000000    test_loss = 2.788420    test_acc=0.649485
epoch= 185    train_loss = 1.085773    bag_loss = 0.043497    mse_loss = 0.715846 train_acc=0.989744    test_loss = 2.682530    test_acc=0.659794
epoch= 186    train_loss = 1.298795    bag_loss = 0.256439    mse_loss = 0.715987 train_acc=0.907692    test_loss = 2.990455    test_acc=0.597938
epoch= 187    train_loss = 1.075671    bag_loss = 0.033885    mse_loss = 0.715697 train_acc=0.989744    test_loss = 2.941963    test_acc=0.577320
epoch= 188    train_loss = 1.055096    bag_loss = 0.013872    mse_loss = 0.715331 train_acc=1.000000    test_loss = 2.884994    test_acc=0.587629
epoch= 189    train_loss = 1.053101    bag_loss = 0.012415    mse_loss = 0.715148 train_acc=1.000000    test_loss = 2.864069    test_acc=0.597938
epoch= 190    train_loss = 1.051925    bag_loss = 0.011818    mse_loss = 0.714982 train_acc=1.000000    test_loss = 2.852983    test_acc=0.608247
epoch= 191    train_loss = 1.050911    bag_loss = 0.011423    mse_loss = 0.714823 train_acc=1.000000    test_loss = 2.845344    test_acc=0.608247
epoch= 192    train_loss = 1.050022    bag_loss = 0.011197    mse_loss = 0.714667 train_acc=1.000000    test_loss = 2.837360    test_acc=0.618557
epoch= 193    train_loss = 1.049194    bag_loss = 0.011077    mse_loss = 0.714513 train_acc=1.000000    test_loss = 2.832819    test_acc=0.618557
epoch= 194    train_loss = 1.048380    bag_loss = 0.011012    mse_loss = 0.714364 train_acc=1.000000    test_loss = 2.829140    test_acc=0.618557
epoch= 195    train_loss = 1.047522    bag_loss = 0.010951    mse_loss = 0.714219 train_acc=1.000000    test_loss = 2.824123    test_acc=0.618557
epoch= 196    train_loss = 1.046657    bag_loss = 0.010928    mse_loss = 0.714078 train_acc=1.000000    test_loss = 2.818382    test_acc=0.618557
epoch= 197    train_loss = 1.045917    bag_loss = 0.011064    mse_loss = 0.713947 train_acc=1.000000    test_loss = 2.807516    test_acc=0.618557
epoch= 198    train_loss = 1.045157    bag_loss = 0.011216    mse_loss = 0.713816 train_acc=1.000000    test_loss = 2.793066    test_acc=0.618557
[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]
[0.9871088266372681, 0.9999548196792603, 0.9999994039535522, 0.7781214118003845, 0.12302824854850769, 0.8809600472450256, 0.3538092374801636, 0.44995173811912537, 0.9999191761016846, 0.9548734426498413, 0.9993352890014648, 0.9996784925460815, 0.04134991765022278, 0.5506877303123474, 0.9999973773956299, 0.25874650478363037, 0.9967031478881836, 0.9179705381393433, 0.9970943927764893, 0.9545761346817017, 0.705376386642456, 6.900643711560406e-06, 0.9999887347221375, 0.4383891522884369, 0.9998601675033569, 0.37160271406173706, 6.322553963400424e-05, 0.9996137619018555, 0.9333489537239075, 0.9999728202819824, 0.9984062314033508, 0.7844415903091431, 0.15909922122955322, 0.9996134638786316, 0.9999946355819702, 0.34840309619903564, 0.001496642827987671, 0.9997992515563965, 0.4554886817932129, 0.8146932125091553, 0.5974268913269043, 0.9999843835830688, 0.9999935626983643, 0.9996068477630615, 1.0, 0.9894633889198303, 0.9999910593032837, 0.9774171113967896, 0.9999755620956421, 0.9776225686073303, 0.9997760057449341, 0.0010690689086914062, 0.5053582191467285, 0.9933998584747314, 0.7559343576431274, 0.9985013008117676, 0.6393741369247437, 0.9999920129776001, 0.9998509287834167, 0.9158210754394531, 0.999565064907074, 0.9778091907501221, 0.9998136162757874, 0.9827698469161987, 0.7260296940803528, 0.999312162399292, 0.9358812570571899, 0.9546797275543213, 0.3030095398426056, 0.9989213943481445, 0.998778223991394, 1.6884688136542536e-07, 0.9891514778137207, 0.5581679940223694, 0.9931488633155823, 0.980427086353302, 0.9998311996459961, 0.800640344619751, 5.671915459970478e-06, 0.9964950084686279, 0.10498538613319397, 0.03420040011405945, 0.999043345451355, 0.9991908073425293, 0.9995822310447693, 0.8979189991950989, 0.5860922336578369, 0.9999858140945435, 0.9976269006729126, 0.984602689743042, 0.9982005953788757, 0.9998411536216736, 0.1918933391571045, 0.0038036704063415527, 0.00042572617530822754, 0.9944350719451904, 0.3535395562648773]
epoch= 199    train_loss = 1.044100    bag_loss = 0.011120    mse_loss = 0.713681 train_acc=1.000000    test_loss = 2.772756    test_acc=0.608247
Ground truth: [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], Predicted: [0.9871088266372681, 0.9999548196792603, 0.9999994039535522, 0.7781214118003845, 0.12302824854850769, 0.8809600472450256, 0.3538092374801636, 0.44995173811912537, 0.9999191761016846, 0.9548734426498413, 0.9993352890014648, 0.9996784925460815, 0.04134991765022278, 0.5506877303123474, 0.9999973773956299, 0.25874650478363037, 0.9967031478881836, 0.9179705381393433, 0.9970943927764893, 0.9545761346817017, 0.705376386642456, 6.900643711560406e-06, 0.9999887347221375, 0.4383891522884369, 0.9998601675033569, 0.37160271406173706, 6.322553963400424e-05, 0.9996137619018555, 0.9333489537239075, 0.9999728202819824, 0.9984062314033508, 0.7844415903091431, 0.15909922122955322, 0.9996134638786316, 0.9999946355819702, 0.34840309619903564, 0.001496642827987671, 0.9997992515563965, 0.4554886817932129, 0.8146932125091553, 0.5974268913269043, 0.9999843835830688, 0.9999935626983643, 0.9996068477630615, 1.0, 0.9894633889198303, 0.9999910593032837, 0.9774171113967896, 0.9999755620956421, 0.9776225686073303, 0.9997760057449341, 0.0010690689086914062, 0.5053582191467285, 0.9933998584747314, 0.7559343576431274, 0.9985013008117676, 0.6393741369247437, 0.9999920129776001, 0.9998509287834167, 0.9158210754394531, 0.999565064907074, 0.9778091907501221, 0.9998136162757874, 0.9827698469161987, 0.7260296940803528, 0.999312162399292, 0.9358812570571899, 0.9546797275543213, 0.3030095398426056, 0.9989213943481445, 0.998778223991394, 1.6884688136542536e-07, 0.9891514778137207, 0.5581679940223694, 0.9931488633155823, 0.980427086353302, 0.9998311996459961, 0.800640344619751, 5.671915459970478e-06, 0.9964950084686279, 0.10498538613319397, 0.03420040011405945, 0.999043345451355, 0.9991908073425293, 0.9995822310447693, 0.8979189991950989, 0.5860922336578369, 0.9999858140945435, 0.9976269006729126, 0.984602689743042, 0.9982005953788757, 0.9998411536216736, 0.1918933391571045, 0.0038036704063415527, 0.00042572617530822754, 0.9944350719451904, 0.3535395562648773]
Runs: 0, Training fold:2
AUC =  0.600921658986175
Mean accuracy =  0.6165228978189213
Acc std =  0.02425118372108647
Mean AUC =  0.6286118748574698
AUC std =  0.0

Process finished with exit code 0


